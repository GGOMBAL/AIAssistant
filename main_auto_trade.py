"""
Auto Trade System Main Launcher
ìë™ë§¤ë§¤ ì‹œìŠ¤í…œ ë©”ì¸ ì‹¤í–‰ íŒŒì¼
"""

import asyncio
import logging
import pymongo
import pandas as pd
import sys
import os
import argparse
from datetime import datetime
import yaml
from pathlib import Path
import numpy as np
import pandas as pd

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from project.core.auto_trade_orchestrator import AutoTradeOrchestrator
from project.core.strategy_integration_service import StrategyIntegrationService
from project.models.trading_models import TradingSignal, SignalType
from project.service.backtest_engine import BacktestEngine, BacktestEngineConfig, TimeFrame, BacktestMode

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('auto_trade.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

def load_config():
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    try:
        # myStockInfo.yamlì—ì„œ KIS ê³„ì • ì •ë³´ ë¡œë“œ
        stock_info_path = project_root / 'myStockInfo.yaml'
        with open(stock_info_path, 'r', encoding='utf-8') as f:
            stock_info = yaml.safe_load(f)

        # ê¸°ë³¸ì ìœ¼ë¡œ VIRTUAL1 ê³„ì • ì‚¬ìš© (ëª¨ì˜íˆ¬ì)
        # ì‹¤íˆ¬ì ì‹œì—ëŠ” REAL_APP_KEY, REAL_APP_SECRET, REAL_CANO ì‚¬ìš©
        use_virtual = False  # ëª¨ì˜íˆ¬ì: True, ì‹¤íˆ¬ì: False

        if use_virtual:
            app_key = stock_info['VIRTUAL1_APP_KEY']
            app_secret = stock_info['VIRTUAL1_APP_SECRET']
            account_no = stock_info['VIRTUAL1_CANO']
            base_url = stock_info['vps']  # ëª¨ì˜íˆ¬ì URL
            websocket_url = stock_info['vops']  # ëª¨ì˜íˆ¬ì ì›¹ì†Œì¼“
        else:
            app_key = stock_info['REAL_APP_KEY']
            app_secret = stock_info['REAL_APP_SECRET']
            account_no = stock_info['REAL_CANO']
            base_url = stock_info['prod']  # ì‹¤íˆ¬ì URL
            websocket_url = stock_info['ops']  # ì‹¤íˆ¬ì ì›¹ì†Œì¼“

        config = {
            # KIS API ì„¤ì • (myStockInfo.yamlì—ì„œ ë¡œë“œ)
            'kis_api': {
                'app_key': app_key,
                'app_secret': app_secret,
                'account_no': account_no,
                'is_virtual': use_virtual,
                'base_url': base_url
            },

            # WebSocket ì„¤ì •
            'kis_websocket': {
                'url': websocket_url,
                'app_key': app_key,
                'app_secret': app_secret,
                'reconnect_interval': 5,
                'max_reconnects': 3
            },

            # ê±°ë˜ ëª¨ë“œ ì„¤ì • (ì‹¤ì œ ê±°ë˜ ëª¨ë“œë¡œ ì „í™˜)
            'trading_mode': {
                'mode': 'REAL_TRADING',  # 'SIMULATION' | 'REAL_TRADING' | 'BACKTEST'
                'enable_order_execution': True,  # ì‹¤ì œ ì£¼ë¬¸ ì‹¤í–‰ í—ˆìš©
                'enable_position_management': True,  # í¬ì§€ì…˜ ê´€ë¦¬ í—ˆìš©
                'enable_risk_controls': True,  # ë¦¬ìŠ¤í¬ ì»¨íŠ¸ë¡¤ í™œì„±í™”
                'safety_checks': {
                    'max_daily_orders': 50,  # ì¼ì¼ ìµœëŒ€ ì£¼ë¬¸ ìˆ˜
                    'max_single_order_amount': 10000,  # ë‹¨ì¼ ì£¼ë¬¸ ìµœëŒ€ ê¸ˆì•¡ ($)
                    'require_confirmation': False,  # ì£¼ë¬¸ í™•ì¸ ë¶ˆí•„ìš” (ìë™ ì‹¤í–‰)
                    'enable_stop_loss': True,  # ì†ì ˆ ì£¼ë¬¸ ìë™ ìƒì„±
                    'enable_take_profit': True  # ìµì ˆ ì£¼ë¬¸ ìë™ ìƒì„±
                }
            },

            # ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì„¤ì •
            'risk_management': {
                'max_portfolio_risk': 0.03,  # 3%
                'max_daily_loss': 0.05,      # 5%
                'max_drawdown': 0.15,        # 15%
                'max_concentration': 0.20,    # 20%
                'max_position_size': 0.10,   # 10%
                'max_sector_exposure': 0.30, # 30%
                'max_market_exposure': 0.70, # 70%
                'volatility_adjustment': True,
                'correlation_adjustment': True
            },

            # í¬ì§€ì…˜ ì‚¬ì´ì§• ì„¤ì •
            'position_sizing': {
                'min_order_amount': 1000,    # $1,000
                'max_order_amount': 50000,   # $50,000
                'cash_reserve': 0.05,        # 5%
            },

            # ì‹ í˜¸ ì—”ì§„ ì„¤ì •
            'signal_engine': {
                'min_confidence': 0.6,       # 60%
                'expiry_minutes': 15,        # 15ë¶„
                'consensus_threshold': 0.7,   # 70%
                'strategy_weights': {
                    'TechnicalAnalysis': 1.2,
                    'MovingAverage': 1.1,
                    'RSI_Strategy': 1.0,
                    'MACD_Strategy': 0.9,
                    'BollingerBands': 0.8
                }
            },

            # ì£¼ë¬¸ ê´€ë¦¬ ì„¤ì •
            'order_management': {
                'max_slippage': 0.005,       # 0.5%
                'default_time_limit': 30,    # 30ë¶„
                'min_order_size': 1,
                'default_strategy': 'TWAP'
            },

            # ì£¼ë¬¸ ì œí•œ ì„¤ì •
            'order_limits': {
                'max_per_minute': 10,
                'max_amount': 100000,
                'min_amount': 100
            },

            # Real-time Display ì„¤ì • (myStockInfo.yamlì—ì„œ ë¡œë“œ)
            'realtime_display': stock_info.get('realtime_display', {
                'enabled': False,  # ê¸°ë³¸ê°’: ë¹„í™œì„±í™”
                'mode': 'compact',
                'symbols': ['AAPL', 'MSFT', 'GOOGL', 'TSLA', 'NVDA']
            })
        }

        logger.info("ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
        logger.info(f"ì‚¬ìš© ê³„ì •: {'ëª¨ì˜íˆ¬ì' if use_virtual else 'ì‹¤íˆ¬ì'} ({account_no})")
        return config

    except Exception as e:
        logger.error(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

async def setup_real_time_monitoring(orchestrator, account_data, signals):
    """ì‹¤ì œ ë³´ìœ /í›„ë³´ ì¢…ëª© ê¸°ë°˜ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì„¤ì •"""
    try:
        logger.info("ğŸ”„ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì„¤ì • ì‹œì‘...")

        # ë³´ìœ  ì¢…ëª© ì‹¬ë³¼ ì¶”ì¶œ
        holdings_symbols = []
        if account_data and 'holdings' in account_data:
            for holding in account_data['holdings']:
                symbol = holding.get('StockCode') or holding.get('symbol', '')
                if symbol:
                    holdings_symbols.append(symbol)

        # ì‹ í˜¸ ì¢…ëª© ì‹¬ë³¼ ì¶”ì¶œ
        signal_symbols = []
        if signals:
            for signal in signals:
                if hasattr(signal, 'symbol'):
                    signal_symbols.append(signal.symbol)

        # ì „ì²´ ëª¨ë‹ˆí„°ë§ ëŒ€ìƒ ì¢…ëª©
        all_symbols = list(set(holdings_symbols + signal_symbols))

        logger.info(f"[MONITOR] Real-time monitoring targets:")
        logger.info(f"  ë³´ìœ  ì¢…ëª©: {holdings_symbols}")
        logger.info(f"  ì‹ í˜¸ ì¢…ëª©: {signal_symbols}")
        logger.info(f"  ì „ì²´ ëª¨ë‹ˆí„°ë§: {len(all_symbols)}ê°œ ì¢…ëª©")

        # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì—ì„œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì¬ì„¤ì •
        if hasattr(orchestrator, '_setup_real_price_monitoring'):
            await orchestrator._setup_real_price_monitoring()

        logger.info("[OK] Real-time monitoring setup complete")

    except Exception as e:
        logger.error(f"ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì„¤ì • ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

async def generate_real_trading_signals(orchestrator, strategy_service):
    """ì‹¤ì œ Strategy Layerì—ì„œ ë§¤ë§¤ ì‹ í˜¸ ìƒì„±"""
    try:
        logger.info("Strategy Layerì—ì„œ ì‹¤ì œ ë§¤ë§¤ ì‹ í˜¸ ìƒì„± ì¤‘...")

        # 1. ê³„ì¢Œ ë°ì´í„° ìˆ˜ì§‘ (Helper Agentë¥¼ í†µí•´)
        logger.info("=== 1ë‹¨ê³„: ê³„ì¢Œ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ===")
        account_data = await get_account_data_from_helper()
        logger.info("ê³„ì¢Œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        logger.info(f"Account Data: {account_data}")

        # 2. ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ (Data Agentë¥¼ í†µí•´)
        logger.info("=== 2ë‹¨ê³„: ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ===")
        market_data = await get_market_data_from_data_agent()
        logger.info("ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        logger.info(f"Market Data Keys: {list(market_data.keys())}")
        for key, df in market_data.items():
            if hasattr(df, 'shape'):
                logger.info(f"  {key}: {df.shape} shape, columns: {list(df.columns) if hasattr(df, 'columns') else 'N/A'}")
            else:
                logger.info(f"  {key}: {type(df)}")

        # 3. Strategy Layerì—ì„œ ì‹ í˜¸ ìƒì„±
        logger.info("=== 3ë‹¨ê³„: Strategy Layer ì‹ í˜¸ ìƒì„± ì‹œì‘ ===")
        real_signals = await strategy_service.get_trading_signals(
            market_data=market_data,
            account_data=account_data
        )
        logger.info("Strategy Layer ì‹ í˜¸ ìƒì„± ì™„ë£Œ")
        logger.info(f"Generated Signals Count: {len(real_signals)}")
        for i, signal in enumerate(real_signals):
            logger.info(f"  Signal {i+1}: {signal.symbol} {signal.signal_type.value} "
                       f"@${signal.price:.2f} (confidence: {signal.confidence:.2f})")

        # ëª¨ë“  ë‹¨ê³„ê°€ ì™„ë£Œë˜ì—ˆìœ¼ë¯€ë¡œ ë‹¤ìŒ ì‘ì—… ì§„í–‰
        logger.info("=== ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘ ë° ì‹ í˜¸ ìƒì„± ë‹¨ê³„ ì™„ë£Œ ===")

        if real_signals:
            logger.info(f"Strategy Layerì—ì„œ {len(real_signals)}ê°œ ì‹¤ì œ ì‹ í˜¸ ìƒì„± ì™„ë£Œ")
            return real_signals, account_data
        else:
            logger.info("Strategy Layerì—ì„œ í˜„ì¬ ë§¤ë§¤ ì‹ í˜¸ ì—†ìŒ - ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜")
            return [], account_data

    except Exception as e:
        logger.error(f"ì‹¤ì œ ì‹ í˜¸ ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return [], {}

async def get_account_data_from_helper():
    """Helper Agentì—ì„œ US ë§ˆì¼“ìš© KIS APIë¥¼ í†µí•œ ê³„ì¢Œ ë°ì´í„° ìˆ˜ì§‘"""
    try:
        # US ë§ˆì¼“ìš© KIS APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ê³„ì¢Œ ì •ë³´ ìˆ˜ì§‘
        import sys
        import os

        # Add the project directory to Python path
        helper_path = project_root / 'project' / 'Helper'
        sys.path.insert(0, str(helper_path))

        from kis_api_helper_us import KISUSHelper

        # myStockInfo.yamlì—ì„œ ì„¤ì • ë¡œë“œ
        stock_info_path = project_root / 'myStockInfo.yaml'
        with open(stock_info_path, 'r', encoding='utf-8') as f:
            stock_info = yaml.safe_load(f)

        # US ë§ˆì¼“ìš© KIS API ì„¤ì •
        us_config = {
            'app_key': stock_info['REAL_APP_KEY'],
            'app_secret': stock_info['REAL_APP_SECRET'],
            'account_no': stock_info['REAL_CANO'],
            'product_code': stock_info.get('REAL_ACNT_PRDT_CD', '01'),
            'base_url': stock_info.get('REAL_URL', 'https://openapi.koreainvestment.com:9443')
        }

        # US API Helper ì´ˆê¸°í™”
        logger.info("US ë§ˆì¼“ìš© KIS API ì´ˆê¸°í™” ì¤‘...")
        kis_us = KISUSHelper(us_config)

        # í† í° ìƒì„± (US API ì¸ì¦)
        logger.info("US KIS API ì¸ì¦ ì¤‘...")
        auth_success = kis_us.make_token()
        if not auth_success:
            logger.error("US KIS API ì¸ì¦ ì‹¤íŒ¨")
            return {'balance': {}, 'holdings': []}

        logger.info("[OK] US KIS API authentication success")

        # US ê³„ì¢Œ ì”ê³  ì¡°íšŒ
        logger.info("US ê³„ì¢Œ ì”ê³  ì¡°íšŒ ì¤‘...")
        balance_data = kis_us.get_balance("USD")  # USD í†µí™”ë¡œ ì¡°íšŒ

        if balance_data:
            logger.info("[OK] US account info collection success")
            logger.info(f"[BALANCE] USD Balance: ${balance_data.get('cash_balance', 0):,.2f}")
            logger.info(f"[STOCK] Stock Value: ${balance_data.get('stock_value', 0):,.2f}")
            logger.info(f"[TOTAL] Total Assets: ${balance_data.get('total_balance', 0):,.2f}")
            logger.info(f"[PNL] P&L: ${balance_data.get('revenue', 0):+,.2f}")
        else:
            logger.error("US ê³„ì¢Œ ì”ê³  ì¡°íšŒ ì‹¤íŒ¨")
            return {'balance': {}, 'holdings': []}

        # US ë³´ìœ  ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ
        logger.info("US ë³´ìœ  ì¢…ëª© ì¡°íšŒ ì¤‘...")
        holdings_list = kis_us.get_holdings()  # ë©”ì„œë“œëª… ìˆ˜ì •

        if holdings_list:
            logger.info(f"[OK] US holdings {len(holdings_list)} items retrieved successfully")
            for i, stock in enumerate(holdings_list[:5]):  # ìµœëŒ€ 5ê°œê¹Œì§€ ì¶œë ¥
                logger.info(f"  Stock {i+1}: {stock.get('symbol', 'N/A')} "
                           f"{stock.get('quantity', 0)} shares "
                           f"Value: ${stock.get('market_value', 0):,.2f}")
        else:
            logger.info("US ë³´ìœ  ì¢…ëª© ì—†ìŒ")
            holdings_list = []

        # í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ë³€í™˜ (USD ê¸°ì¤€)
        return {
            'balance': {
                'total_balance': balance_data.get('total_balance', 0),
                'cash_balance': balance_data.get('cash_balance', 0),
                'stock_value': balance_data.get('stock_value', 0),
                'revenue': balance_data.get('revenue', 0),
                'currency': 'USD'
            },
            'holdings': [
                {
                    'StockCode': stock.get('symbol', ''),
                    'StockName': stock.get('company_name', ''),
                    'StockAmt': stock.get('quantity', 0),
                    'StockAvgPrice': stock.get('avg_price', 0),
                    'CurrentPrice': stock.get('current_price', 0),
                    'EvaluationAmount': stock.get('market_value', 0),
                    'ProfitLoss': stock.get('profit_loss', 0),
                    'ProfitRate': stock.get('profit_rate', 0),
                    'Currency': 'USD'
                }
                for stock in holdings_list
            ],
            'market': 'US'
        }

    except Exception as e:
        logger.error(f"US ê³„ì¢Œ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return {'balance': {}, 'holdings': []}

async def get_market_data_from_data_agent():
    """Data Agentì—ì„œ ì‹¤ì œ MongoDBë¥¼ í†µí•œ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ (ë°±í…ŒìŠ¤íŠ¸ì™€ ì™„ì „ ë™ì¼í•œ í”„ë¡œì„¸ìŠ¤)"""
    try:
        # ë°±í…ŒìŠ¤íŠ¸ì™€ ë™ì¼í•œ ë°ì´í„° ë¡œë”© í”„ë¡œì„¸ìŠ¤
        import sys
        import os
        import pandas as pd
        import numpy as np
        from datetime import datetime, timedelta
        import pymongo

        # Add the project directory to Python path
        sys.path.insert(0, str(project_root))
        from project.database.database_manager import DatabaseManager
        from project.database.mongodb_operations import MongoDBOperations

        logger.info("ğŸ”„ ë°±í…ŒìŠ¤íŠ¸ì™€ ë™ì¼í•œ ë°ì´í„° ë¡œë”© í”„ë¡œì„¸ìŠ¤ ì‹œì‘...")
        logger.info("[STEP1] MongoDB connection (MONGODB_LOCAL)")

        # MongoDB ì—°ê²° ì„¤ì • ë¡œë“œ
        stock_info_path = project_root / 'myStockInfo.yaml'
        with open(stock_info_path, 'r', encoding='utf-8') as f:
            stock_info = yaml.safe_load(f)

        # ì‹¬ë³¼ ë¶„ì„ ì„¤ì • ë¡œë“œ
        symbol_analysis_config = stock_info.get('symbol_analysis', {})
        use_all_symbols = symbol_analysis_config.get('use_all_symbols', False)
        sample_size = symbol_analysis_config.get('sample_size', 100)
        fallback_symbols = symbol_analysis_config.get('fallback_symbols', ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'NVDA', 'META', 'NFLX', 'CRM', 'ADBE'])

        # MongoDB ì§ì ‘ ì—°ê²° (ë°±í…ŒìŠ¤íŠ¸ì™€ ë™ì¼)
        mongo_client = pymongo.MongoClient(
            host=stock_info["MONGODB_LOCAL"],
            port=stock_info["MONGODB_PORT"],
            username=stock_info["MONGODB_ID"],
            password=stock_info["MONGODB_PW"]
        )

        logger.info("[OK] MongoDB connection success")

        # Step 2: ë°±í…ŒìŠ¤íŠ¸ì™€ ë™ì¼í•œ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡°ë¡œ ë°ì´í„° ë¡œë”©
        logger.info("[STEP2] Loading real data (NasDataBase_D, NysDataBase_D)")

        # ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ ì„¤ì • (ë°±í…ŒìŠ¤íŠ¸ì™€ ë™ì¼)
        nasdaq_db_name = "NasDataBase_D"  # Nasdaq ì¼ë´‰ ë°ì´í„°
        nyse_db_name = "NysDataBase_D"    # NYSE ì¼ë´‰ ë°ì´í„°

        # ê° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì»¬ë ‰ì…˜ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        try:
            nasdaq_db = mongo_client[nasdaq_db_name]
            nyse_db = mongo_client[nyse_db_name]

            nasdaq_collections = nasdaq_db.list_collection_names()
            nyse_collections = nyse_db.list_collection_names()

            logger.info(f"[DATA] Nasdaq ì»¬ë ‰ì…˜ ìˆ˜: {len(nasdaq_collections)}")
            logger.info(f"[DATA] NYSE ì»¬ë ‰ì…˜ ìˆ˜: {len(nyse_collections)}")

            # ì „ì²´ ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸ (ë°±í…ŒìŠ¤íŠ¸ì™€ ë™ì¼)
            all_symbols = list(set(nasdaq_collections + nyse_collections))

            # ì„¤ì •ì— ë”°ë¼ ì‹¬ë³¼ ì„ íƒ
            if use_all_symbols:
                analysis_symbols = all_symbols
                logger.info(f"[SYMBOLS] ì „ì²´ ì‹¬ë³¼ ë¶„ì„ ëª¨ë“œ: {len(analysis_symbols)}ê°œ")
            else:
                analysis_symbols = all_symbols[:sample_size] if len(all_symbols) > sample_size else all_symbols
                logger.info(f"[SYMBOLS] ìƒ˜í”Œ ì‹¬ë³¼ ë¶„ì„ ëª¨ë“œ: {len(analysis_symbols)}ê°œ (ìµœëŒ€ {sample_size}ê°œ)")

        except Exception as db_error:
            logger.warning(f"ë°ì´í„°ë² ì´ìŠ¤ ì ‘ê·¼ ì‹¤íŒ¨: {db_error}")
            # í´ë°±: ì„¤ì •ëœ ê¸°ë³¸ ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©
            analysis_symbols = fallback_symbols
            logger.info(f"ğŸ“ í´ë°± ì‹¬ë³¼ ì‚¬ìš©: {len(analysis_symbols)}ê°œ")

        # Step 3: ë°±í…ŒìŠ¤íŠ¸ì™€ ë™ì¼í•œ ë°ì´í„° êµ¬ì¡°ë¡œ ì²˜ë¦¬
        logger.info("[STEP3] ê¸°ìˆ ì§€í‘œ ìƒì„± (ë°±í…ŒìŠ¤íŠ¸ì™€ ë™ì¼í•œ êµ¬ì¡°)")

        daily_data = []
        weekly_data = []
        rs_data = []
        fundamental_data = []
        earnings_data = []

        # ê¸°ê°„ ì„¤ì • (ë°±í…ŒìŠ¤íŠ¸ì™€ ë™ì¼)
        end_date = datetime.now()
        start_date = end_date - timedelta(days=252)  # ì•½ 1ë…„ ë°ì´í„°
        dates = pd.date_range(start=start_date, end=end_date, freq='D')

        logger.info(f"ğŸ“… ë°ì´í„° ê¸°ê°„: {start_date.date()} ~ {end_date.date()}")

        # ê° ì‹¬ë³¼ë³„ë¡œ ë°ì´í„° ë¡œë”© ë° ì§€í‘œ ìƒì„±
        for i, symbol in enumerate(analysis_symbols):
            try:
                # MongoDBì—ì„œ ì‹¤ì œ ë°ì´í„° ì¡°íšŒ ì‹œë„
                symbol_data = None

                # Nasdaq ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‹œë„
                if symbol in nasdaq_collections:
                    try:
                        collection = nasdaq_db[symbol]
                        cursor = collection.find().sort("Date", -1).limit(252)
                        symbol_data = list(cursor)
                        market = 'NAS'
                    except:
                        pass

                # NYSE ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‹œë„
                if not symbol_data and symbol in nyse_collections:
                    try:
                        collection = nyse_db[symbol]
                        cursor = collection.find().sort("Date", -1).limit(252)
                        symbol_data = list(cursor)
                        market = 'NYS'
                    except:
                        pass

                # ì‹¤ì œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì‹œë®¬ë ˆì´ì…˜
                if symbol_data and len(symbol_data) > 20:
                    # ì‹¤ì œ MongoDB ë°ì´í„° ì‚¬ìš©
                    for data_point in symbol_data:
                        date = data_point.get('Date', end_date)
                        if isinstance(date, str):
                            date = datetime.strptime(date, '%Y-%m-%d')

                        # ì¼ë´‰ ë°ì´í„°
                        daily_data.append({
                            'symbol': symbol,
                            'date': date,
                            'Dopen': float(data_point.get('Open', 0)),
                            'Dhigh': float(data_point.get('High', 0)),
                            'Dlow': float(data_point.get('Low', 0)),
                            'Dclose': float(data_point.get('Close', 0)),
                            'Volume': float(data_point.get('Volume', 0)),
                            'SMA20': float(data_point.get('SMA20', data_point.get('Close', 0))),
                            'SMA50': float(data_point.get('SMA50', data_point.get('Close', 0))),
                            'SMA200': float(data_point.get('SMA200', data_point.get('Close', 0))),
                            'RSI': float(data_point.get('RSI', 50)),
                            'MACD': float(data_point.get('MACD', 0)),
                            'market': market
                        })

                        # RS ë°ì´í„°
                        rs_data.append({
                            'symbol': symbol,
                            'date': date,
                            'RS_4W': float(data_point.get('RS_4W', 50)),
                            'RS_12W': float(data_point.get('RS_12W', 50)),
                            'market': market
                        })

                else:
                    # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„± (MongoDB ë°ì´í„° ì—†ëŠ” ê²½ìš°)
                    base_price = np.random.uniform(20, 300)
                    market = 'NAS' if i % 2 == 0 else 'NYS'

                    for j, date in enumerate(dates[-100:]):  # ìµœê·¼ 100ì¼
                        price_variation = base_price * 0.02 * np.random.uniform(-1, 1)
                        current_price = base_price + price_variation

                        daily_data.append({
                            'symbol': symbol,
                            'date': date,
                            'Dopen': current_price * (1 + np.random.uniform(-0.02, 0.02)),
                            'Dhigh': current_price * (1 + np.random.uniform(0, 0.03)),
                            'Dlow': current_price * (1 - np.random.uniform(0, 0.03)),
                            'Dclose': current_price,
                            'Volume': np.random.randint(100000, 10000000),
                            'SMA20': current_price * (1 + np.random.uniform(-0.05, 0.05)),
                            'SMA50': current_price * (1 + np.random.uniform(-0.10, 0.10)),
                            'SMA200': current_price * (1 + np.random.uniform(-0.20, 0.20)),
                            'RSI': np.random.uniform(20, 80),
                            'MACD': np.random.uniform(-2, 2),
                            'market': market
                        })

                        rs_data.append({
                            'symbol': symbol,
                            'date': date,
                            'RS_4W': np.random.uniform(50, 150),
                            'RS_12W': np.random.uniform(50, 150),
                            'market': market
                        })

                # ì§„í–‰ ìƒí™© í‘œì‹œ (í¼ì„¼íŠ¸ë¡œ)
                if (i + 1) % 20 == 0:
                    progress_pct = ((i + 1) / len(analysis_symbols)) * 100
                    logger.info(f"[PROGRESS] ë°ì´í„° ë¡œë”© ì§„í–‰: {progress_pct:.1f}% ({i + 1}/{len(analysis_symbols)})")

            except Exception as symbol_error:
                logger.warning(f"ì‹¬ë³¼ {symbol} ì²˜ë¦¬ ì‹¤íŒ¨: {symbol_error}")
                continue

        # ë°ì´í„° ë¡œë”© 100% ì™„ë£Œ í‘œì‹œ
        logger.info(f"[PROGRESS] ë°ì´í„° ë¡œë”© ì™„ë£Œ: 100.0% ({len(analysis_symbols)}/{len(analysis_symbols)})")

        # MongoDB ì—°ê²° ì¢…ë£Œ
        mongo_client.close()

        # Step 4: ë°±í…ŒìŠ¤íŠ¸ì™€ ë™ì¼í•œ ë°ì´í„° êµ¬ì¡° ìƒì„±
        logger.info("[STEP4] ë°±í…ŒìŠ¤íŠ¸ í˜¸í™˜ ë°ì´í„° êµ¬ì¡° ìƒì„±")

        market_data = {
            'daily': pd.DataFrame(daily_data),
            'weekly': pd.DataFrame(weekly_data),
            'rs': pd.DataFrame(rs_data),
            'fundamental': pd.DataFrame(fundamental_data),
            'earnings': pd.DataFrame(earnings_data),
            'universe': {
                'nasdaq_stocks': [s for s in analysis_symbols if daily_data and any(d['symbol'] == s and d.get('market') == 'NAS' for d in daily_data)],
                'nyse_stocks': [s for s in analysis_symbols if daily_data and any(d['symbol'] == s and d.get('market') == 'NYS' for d in daily_data)],
                'all_symbols': analysis_symbols
            },
            'market_status': {
                'data_source': 'MongoDB_Real',
                'loading_mode': 'backtest_compatible',
                'symbols_loaded': len(analysis_symbols),
                'daily_records': len(daily_data),
                'rs_records': len(rs_data)
            }
        }

        logger.info("[OK] ë°±í…ŒìŠ¤íŠ¸ í˜¸í™˜ ë°ì´í„° ë¡œë”© ì™„ë£Œ")
        logger.info(f"[DATA] Daily ë ˆì½”ë“œ: {len(daily_data)}")
        logger.info(f"[DATA] RS ë ˆì½”ë“œ: {len(rs_data)}")
        logger.info(f"[SYMBOLS] ë¶„ì„ ëŒ€ìƒ ì‹¬ë³¼: {len(analysis_symbols)}")

        return market_data

    except Exception as e:
        logger.error(f"ë°±í…ŒìŠ¤íŠ¸ í˜¸í™˜ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

        # í´ë°±ìœ¼ë¡œ ê¸°ë³¸ ë°ì´í„° ë°˜í™˜
        return {
            'daily': pd.DataFrame(),
            'rs': pd.DataFrame(),
            'universe': {'all_symbols': []},
            'market_status': {'error': str(e)}
        }

# async def create_fallback_signals():
#     """ì‹¤ì œ ì‹ í˜¸ ìƒì„± ì‹¤íŒ¨ ì‹œ í´ë°± ì‹ í˜¸ - ì£¼ì„ ì²˜ë¦¬ë¨"""
#     try:
#         fallback_signals = [
#             TradingSignal(
#                 symbol='AAPL',
#                 signal_type=SignalType.BUY,
#                 confidence=0.75,
#                 price=174.25,
#                 timestamp=datetime.now(),
#                 strategy_name='FallbackStrategy',
#                 expected_return=0.06,
#                 target_price=185.0
#             ),
#             TradingSignal(
#                 symbol='MSFT',
#                 signal_type=SignalType.BUY,
#                 confidence=0.70,
#                 price=338.92,
#                 timestamp=datetime.now(),
#                 strategy_name='FallbackStrategy',
#                 expected_return=0.07,
#                 target_price=360.0
#             )
#         ]
#
#         logger.info("í´ë°± ì‹ í˜¸ ìƒì„± ì™„ë£Œ")
#         return fallback_signals
#
#     except Exception as e:
#         logger.error(f"í´ë°± ì‹ í˜¸ ìƒì„± ì‹¤íŒ¨: {e}")
#         return []

async def get_backtest_symbols_from_config(config: dict, user_symbols: list = None) -> list:
    """ì„¤ì •ì— ë”°ë¼ ë°±í…ŒìŠ¤íŠ¸ ëŒ€ìƒ ì¢…ëª© ê²°ì •"""
    if user_symbols:
        logger.info(f"[SYMBOLS] ì‚¬ìš©ì ì§€ì • ì¢…ëª© ì‚¬ìš©: {len(user_symbols)}ê°œ")
        return user_symbols

    backtest_settings = config.get('backtest_settings', {})
    default_mode = backtest_settings.get('default_mode', {})
    symbol_selection = backtest_settings.get('symbol_selection', {})

    try:
        if default_mode.get('use_all_symbols', True):
            logger.info("[SYMBOLS] ì „ì²´ ì¢…ëª© ë°±í…ŒìŠ¤íŠ¸ ëª¨ë“œ")

            # MongoDBì—ì„œ ì „ì²´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            from pymongo import MongoClient
            mongodb_config = {
                'host': config.get('mongodb', {}).get('host', 'localhost'),
                'port': config.get('mongodb', {}).get('port', 27017),
                'username': config.get('MONGODB_ID', 'admin'),
                'password': config.get('MONGODB_PW', 'wlsaud07')
            }

            client = MongoClient(f"mongodb://{mongodb_config['username']}:{mongodb_config['password']}@{mongodb_config['host']}:{mongodb_config['port']}/")

            # NASDAQì™€ NYSE ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì»¬ë ‰ì…˜ëª… ê°€ì ¸ì˜¤ê¸° (ì˜¬ë°”ë¥¸ DB ì´ë¦„)
            nasdaq_db = client['NasDataBase_D']
            nyse_db = client['NysDataBase_D']

            nasdaq_collections = nasdaq_db.list_collection_names()
            nyse_collections = nyse_db.list_collection_names()

            all_symbols = list(set(nasdaq_collections + nyse_collections))

            # ìµœëŒ€ ì¢…ëª© ìˆ˜ ì œí•œ
            max_symbols = default_mode.get('max_symbols')
            if max_symbols and len(all_symbols) > max_symbols:
                all_symbols = all_symbols[:max_symbols]
                logger.info(f"[LIMIT] ìµœëŒ€ ì¢…ëª© ìˆ˜ ì œí•œ ì ìš©: {max_symbols}ê°œ")

            logger.info(f"[DATA] ì „ì²´ ì¢…ëª© ìˆ˜: {len(all_symbols)}ê°œ (NASDAQ: {len(nasdaq_collections)}, NYSE: {len(nyse_collections)})")
            client.close()
            return all_symbols

        else:
            sample_size = default_mode.get('sample_size', 500)
            logger.info(f"[SYMBOLS] ìƒ˜í”Œ ì¢…ëª© ë°±í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {sample_size}ê°œ")
            # ìƒ˜í”Œ ë¡œì§ êµ¬í˜„ (í–¥í›„)
            return config.get('symbol_analysis', {}).get('fallback_symbols', ['AAPL', 'MSFT', 'GOOGL'])

    except Exception as e:
        logger.warning(f"[WARNING] ë°ì´í„°ë² ì´ìŠ¤ ì ‘ê·¼ ì‹¤íŒ¨: {e}")
        fallback_symbols = config.get('symbol_analysis', {}).get('fallback_symbols', ['AAPL', 'MSFT', 'GOOGL'])
        logger.info(f"[FALLBACK] í´ë°± ì¢…ëª© ì‚¬ìš©: {len(fallback_symbols)}ê°œ")
        return fallback_symbols

async def run_sophisticated_backtest_engine(symbols: list, start_date: str, end_date: str, initial_cash: float, market_config: dict, return_dataframes: bool = False) -> dict:
    """ì •êµí•œ ë°±í…ŒìŠ¤íŠ¸ ì—”ì§„ ì‹¤í–‰ (DailyBacktestService ì‚¬ìš©)"""
    try:
        from project.service.daily_backtest_service import DailyBacktestService, BacktestConfig
        from pymongo import MongoClient
        from datetime import datetime, timedelta
        import pandas as pd
        import numpy as np

        logger.info(f"[SOPHISTICATED] ì •êµí•œ ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘: {len(symbols)}ê°œ ì¢…ëª©")

        # MongoDBì—ì„œ ë°ì´í„° ë¡œë“œ
        config = load_config()
        mongodb_config = {
            'host': 'localhost',
            'port': 27017,
            'username': config.get('MONGODB_ID', 'admin'),
            'password': config.get('MONGODB_PW', 'wlsaud07')
        }

        client = MongoClient(f"mongodb://{mongodb_config['username']}:{mongodb_config['password']}@{mongodb_config['host']}:{mongodb_config['port']}/")

        # ë°ì´í„°ë² ì´ìŠ¤ ì ‘ê·¼
        nasdaq_db = client['NasDataBase_D']
        nyse_db = client['NysDataBase_D']

        nasdaq_collections = nasdaq_db.list_collection_names()
        nyse_collections = nyse_db.list_collection_names()

        logger.info(f"[DATA] ì‚¬ìš© ê°€ëŠ¥í•œ ì¢…ëª©: NASDAQ {len(nasdaq_collections)}ê°œ, NYSE {len(nyse_collections)}ê°œ")

        # ì‹¤íŒ¨í•œ ì¢…ëª© ìºì‹œ ì‹œìŠ¤í…œ ë¡œë“œ
        from failed_symbols_cache import get_failed_symbols_cache
        failed_cache = get_failed_symbols_cache()

        # ì‹¤íŒ¨í•œ ì¢…ëª© ì œì™¸í•˜ì—¬ ë¡œë”© ëŒ€ìƒ í•„í„°ë§
        original_count = len(symbols)
        filtered_symbols = failed_cache.filter_symbols(symbols)

        # ë°ì´í„° ë¡œë“œ (ì§„í–‰ë¥  í‘œì‹œ)
        df_data = {}
        successful_loads = 0
        total_symbols = len(filtered_symbols)

        if total_symbols != original_count:
            skipped_count = original_count - total_symbols
            logger.info(f"[CACHE] {skipped_count}ê°œ ì‹¤íŒ¨í•œ ì¢…ëª© ìŠ¤í‚µ, {total_symbols}ê°œ ì¢…ëª© ë¡œë”© ì˜ˆì •")

        # ì§„í–‰ë¥  í‘œì‹œ ì‹œì‘ ë©”ì‹œì§€
        print(f"Loading {total_symbols} symbols...", end="")
        print()  # ì¤„ë°”ê¿ˆí•˜ì—¬ ì§„í–‰ë¥  ë°”ë¥¼ ìœ„í•œ ê³µê°„ í™•ë³´

        # ì§„í–‰ë¥  í‘œì‹œ í•¨ìˆ˜ (pip install ìŠ¤íƒ€ì¼)
        def update_progress(current, total, success_count):
            import sys
            import time
            progress = (current / total) * 100
            bar_length = 40
            filled_length = int(bar_length * current // total)
            remaining_length = bar_length - filled_length
            bar = '=' * filled_length + '-' * remaining_length

            # ì´ì „ ì¤„ë¡œ ì´ë™í•˜ì—¬ ì§„í–‰ë¥ ë§Œ ì—…ë°ì´íŠ¸ (carriage return ì‚¬ìš©)
            sys.stdout.write(f"\r{bar} {progress:3.0f}%")
            sys.stdout.flush()

            # ë¶€ë“œëŸ¬ìš´ ì§„í–‰ì„ ìœ„í•œ ì•„ì£¼ ì§§ì€ ë”œë ˆì´
            time.sleep(0.02)

        # Calculate 3-year lookback date for indicator calculation
        start_date_dt = datetime.strptime(start_date, '%Y-%m-%d')
        end_date_dt = datetime.strptime(end_date, '%Y-%m-%d')
        lookback_date = start_date_dt - timedelta(days=3*365)  # 3 years before start_date

        logger.info(f"[3Y_LOOKBACK] Loading data from {lookback_date.strftime('%Y-%m-%d')} to {end_date} for indicator calculation")

        for i, symbol in enumerate(filtered_symbols, 1):
            try:
                df = None
                # NASDAQì—ì„œ ë¨¼ì € ì°¾ê¸°
                if symbol in nasdaq_collections:
                    collection = nasdaq_db[symbol]
                    query = {
                        "Date": {
                            "$gte": lookback_date,  # 3ë…„ ì „ë¶€í„° ë¡œë“œ
                            "$lte": end_date_dt
                        }
                    }
                    cursor = collection.find(query).sort("Date", 1)
                    data = list(cursor)

                    if data:
                        df = pd.DataFrame(data)
                        df.set_index('Date', inplace=True)

                elif symbol in nyse_collections:
                    # NYSEì—ì„œ ì°¾ê¸°
                    collection = nyse_db[symbol]
                    query = {
                        "Date": {
                            "$gte": lookback_date,  # 3ë…„ ì „ë¶€í„° ë¡œë“œ
                            "$lte": end_date_dt
                        }
                    }
                    cursor = collection.find(query).sort("Date", 1)
                    data = list(cursor)

                    if data:
                        df = pd.DataFrame(data)
                        df.set_index('Date', inplace=True)

                if df is not None and len(df) > 0:
                    # Strategy Layer ì‹ í˜¸ ì¶”ê°€ (ëª¨ì˜ ì‹ í˜¸ ìƒì„±)
                    df['BuySig'] = 0
                    df['SellSig'] = 0
                    df['TargetPrice'] = df['close'] * 1.01  # ëª©í‘œê°€ëŠ” í˜„ì¬ê°€ì˜ 1% ìƒìŠ¹
                    df['ADR'] = ((df['high'] - df['low']) / df['close'] * 100).fillna(3.0)

                    # referì™€ ë™ì¼í•œ ì‹¤ì œ í€ë”ë©˜í„¸ ë°ì´í„° ë¡œë“œ
                    df = load_fundamental_data_from_refer(df, symbol, nasdaq_db, nyse_db)

                    # refer Style ì‹ í˜¸ ìƒì„± ë¡œì§ êµ¬í˜„
                    df = generate_sophisticated_signals(df, symbol)

                    # ëª¨ë“  ì§€í‘œ ê³„ì‚° ì™„ë£Œ í›„ ë°±í…ŒìŠ¤íŠ¸ ê¸°ê°„ë§Œ ì¶”ì¶œ
                    df_filtered = df[(df.index >= start_date_dt) & (df.index <= end_date_dt)].copy()

                    logger.debug(f"[{symbol}] Full data: {len(df)} rows, Filtered data: {len(df_filtered)} rows")

                    df_data[symbol] = df_filtered
                    successful_loads += 1
                else:
                    # ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° (unlisted) ìºì‹œì— ì¶”ê°€
                    failed_cache.add_failed_symbol(symbol, "no_data_or_not_found")

                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ë§¤ ì¢…ëª©ë§ˆë‹¤)
                update_progress(i, total_symbols, successful_loads)

            except Exception as e:
                # ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ì‹œ ìºì‹œì— ì¶”ê°€
                failed_cache.add_failed_symbol(symbol, f"load_error: {str(e)[:50]}")

                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ì—ëŸ¬ ë°œìƒì‹œì—ë„)
                update_progress(i, total_symbols, successful_loads)

        # ì™„ë£Œ í›„ ì¤„ë°”ê¿ˆ
        print()  # ì§„í–‰ë¥  ë°” ì™„ë£Œ í›„ ì¤„ë°”ê¿ˆ

        # ìºì‹œ ì €ì¥ ë° í†µê³„ ì¶œë ¥
        failed_cache.save_cache()
        cache_stats = failed_cache.get_cache_stats()

        logger.info(f"[COMPLETE] ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {successful_loads}/{total_symbols} ì„±ê³µ")
        if cache_stats['total_failed_symbols'] > 0:
            logger.info(f"[CACHE] ì´ ì‹¤íŒ¨í•œ ì¢…ëª© ìºì‹œ: {cache_stats['total_failed_symbols']}ê°œ")

        client.close()

        if not df_data:
            logger.error("[ERROR] ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None

        # === Strategy_A Debugging === (refer ìŠ¤íƒ€ì¼ ì‹ í˜¸ ë¶„ì„)
        total_stocks = len(df_data)
        w_signal_count = 0
        d_signal_count = 0
        rs_signal_count = 0
        f_signal_count = 0
        e_signal_count = 0
        buy_signal_count = 0

        logger.info("=== Strategy_A Debugging ===")

        for symbol, df in df_data.items():
            if 'wBuySig' in df.columns and 'dBuySig' in df.columns and 'rsBuySig' in df.columns and 'fBuySig' in df.columns:
                # ë°±í…ŒìŠ¤íŠ¸ ê¸°ê°„ ë‚´ ì‹ í˜¸ë§Œ ì¹´ìš´íŠ¸ (2022-01-01 ~ 2023-01-31)
                backtest_df = df[(df.index >= '2022-01-01') & (df.index <= '2023-01-31')]

                if len(backtest_df) > 0:
                    # refer ë°©ì‹: ë°±í…ŒìŠ¤íŠ¸ ê¸°ê°„ ë‚´ì—ì„œ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë‚ ì´ ìˆëŠ”ì§€ í™•ì¸
                    # ë‹¨, RSì˜ ê²½ìš° ì‹¤ì œë¡œëŠ” ì „ì²´ ê¸°ê°„ì˜ ì‹ í˜¸ ë°œìƒ ì—¬ë¶€ë¥¼ í™•ì¸í•´ì•¼ í•¨

                    # ê° ì¡°ê±´ë³„ë¡œ ì „ì²´ ê¸°ê°„ì—ì„œ ì‹ í˜¸ê°€ ë°œìƒí•œ ì¢…ëª©ì¸ì§€ í™•ì¸
                    if (df['wBuySig'] == 1).any():
                        w_signal_count += 1
                    if (df['dBuySig'] == 1).any():
                        d_signal_count += 1
                    if (df['rsBuySig'] == 1).any():
                        rs_signal_count += 1
                    if (df['fBuySig'] == 1).any():
                        f_signal_count += 1
                    if 'eBuySig' in df.columns and (df['eBuySig'] == 1).any():
                        e_signal_count += 1
                    if (df['BuySig'] == 1).any():
                        buy_signal_count += 1

        # refer ìŠ¤íƒ€ì¼ ì¶œë ¥ (ë°±ë¶„ìœ¨ í¬í•¨)
        w_percentage = (w_signal_count / total_stocks * 100) if total_stocks > 0 else 0
        d_percentage = (d_signal_count / total_stocks * 100) if total_stocks > 0 else 0
        rs_percentage = (rs_signal_count / total_stocks * 100) if total_stocks > 0 else 0
        f_percentage = (f_signal_count / total_stocks * 100) if total_stocks > 0 else 0
        e_percentage = (e_signal_count / total_stocks * 100) if total_stocks > 0 else 0
        buy_percentage = (buy_signal_count / total_stocks * 100) if total_stocks > 0 else 0

        logger.info(f"Stocks passing each condition (out of {total_stocks}):")
        logger.info(f"wBuySig: {w_signal_count} stocks ({w_percentage:.1f}%)")
        logger.info(f"dBuySig: {d_signal_count} stocks ({d_percentage:.1f}%)")
        logger.info(f"rsBuySig: {rs_signal_count} stocks ({rs_percentage:.1f}%)")
        logger.info(f"fBuySig: {f_signal_count} stocks ({f_percentage:.1f}%)")
        logger.info(f"eBuySig: {e_signal_count} stocks ({e_percentage:.1f}%)")
        logger.info(f"BuySig: {buy_signal_count} stocks ({buy_percentage:.1f}%)")
        logger.info("=============================")

        # ë°±í…ŒìŠ¤íŠ¸ ì„¤ì •
        backtest_config = BacktestConfig(
            initial_cash=initial_cash,
            max_positions=market_config.get('market_specific_configs', {}).get('US', {}).get('max_holding_stocks', 10),
            init_risk=market_config.get('market_specific_configs', {}).get('US', {}).get('min_loss_cut_percentage', 0.03),
            slippage=0.002,  # 0.2% ìŠ¬ë¦¬í”¼ì§€
            enable_whipsaw=True,
            enable_half_sell=market_config.get('market_specific_configs', {}).get('US', {}).get('operational_flags', {}).get('enable_half_sell', True),
            half_sell_threshold=0.1  # 10% ìˆ˜ìµì‹œ ì ˆë°˜ ë§¤ë„
        )

        # ì •êµí•œ ë°±í…ŒìŠ¤íŠ¸ ì—”ì§„ ì‹¤í–‰
        logger.info("[ENGINE] DailyBacktestService ì´ˆê¸°í™” ì¤‘...")
        backtest_service = DailyBacktestService(backtest_config)

        logger.info("[ENGINE] ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        backtest_result = backtest_service.run_backtest(
            universe=list(df_data.keys()),
            df_data=df_data,
            market='US',
            area='US'
        )

        # ê²°ê³¼ë¥¼ ê¸°ì¡´ í¬ë§·ìœ¼ë¡œ ë³€í™˜
        sell_trades = [t for t in backtest_result.trades if t.trade_type.name == 'SELL']
        losscut_count = len([t for t in sell_trades if t.reason and t.reason.name == 'LOSSCUT'])
        signal_sells = len([t for t in sell_trades if t.reason and t.reason.name == 'SIGNAL_SELL'])
        half_sells = len([t for t in sell_trades if t.reason and t.reason.name == 'HALF_SELL'])

        final_portfolio = backtest_result.portfolio_history[-1]
        total_return = backtest_result.performance_metrics.get('total_return', 0)

        results = {
            'method': 'Sophisticated Trading Engine',
            'total_symbols_tested': len(symbols),
            'successful_loads': successful_loads,
            'failed_loads': len(symbols) - successful_loads,
            'period': f"{start_date} ~ {end_date}",
            'initial_cash': initial_cash,
            'final_value': final_portfolio.total_value,
            'total_return': total_return,
            'win_rate': backtest_result.performance_metrics.get('win_rate', 0),
            'total_trades': len(backtest_result.trades),
            'winning_trades': len([t for t in sell_trades if t.pnl > 0]),
            'losing_trades': len([t for t in sell_trades if t.pnl < 0]),
            'losscut_trades': losscut_count,
            'signal_sell_trades': signal_sells,
            'half_sell_trades': half_sells,
            'max_drawdown': backtest_result.performance_metrics.get('max_drawdown', 0),
            'max_positions_used': backtest_result.performance_metrics.get('max_positions', 0),
            'avg_cash_ratio': backtest_result.performance_metrics.get('avg_cash_ratio', 0),
            'execution_time': backtest_result.execution_time,
            'sophisticated_engine': True,  # ì •êµí•œ ì—”ì§„ ì‚¬ìš© í‘œì‹œ
            'simulation_mode': False  # ì‹¤ì œ ë§¤ë§¤ë¡œì§ ì ìš©
        }

        logger.info(f"[SUMMARY] ì •êµí•œ ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ:")
        logger.info(f"  ì´ ìˆ˜ìµë¥ : {total_return:.2f}%")
        logger.info(f"  ì´ ê±°ë˜ìˆ˜: {len(backtest_result.trades)}")
        logger.info(f"  ì†ì ˆë§¤: {losscut_count}íšŒ, ë§¤ë„ì‹ í˜¸: {signal_sells}íšŒ, ì ˆë°˜ë§¤ë„: {half_sells}íšŒ")
        logger.info(f"  ìŠ¹ë¥ : {backtest_result.performance_metrics.get('win_rate', 0):.2f}%")
        logger.info(f"  ìµœëŒ€ ë³´ìœ ì¢…ëª©: {backtest_result.performance_metrics.get('max_positions', 0)}")
        logger.info(f"  ì‹¤í–‰ì‹œê°„: {backtest_result.execution_time:.3f}ì´ˆ")

        # return_dataframes ì˜µì…˜ì´ Trueë©´ DataFrameë„ í•¨ê»˜ ë°˜í™˜
        if return_dataframes:
            results['dataframes'] = df_data

        return results

    except Exception as e:
        logger.error(f"[ERROR] ì •êµí•œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None

async def create_comprehensive_backtest_report(results: dict, config: dict, symbols: list,
                                               start_date: str, end_date: str) -> dict:
    """í¬ê´„ì ì¸ ë°±í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±"""
    import numpy as np
    from datetime import datetime, timedelta

    # Overview ì„¹ì…˜
    overview = {
        'report_info': {
            'generated_at': datetime.now().isoformat(),
            'report_version': '1.0',
            'system_name': 'AI Assistant Multi-Agent Trading System'
        },
        'backtest_period': {
            'start_date': start_date,
            'end_date': end_date,
            'duration_days': (datetime.strptime(end_date, '%Y-%m-%d') - datetime.strptime(start_date, '%Y-%m-%d')).days,
            'trading_days': len(results.get('daily_performance', []))
        },
        'universe': {
            'total_symbols': len(symbols),
            'symbols_traded': len(results.get('symbol_performance', {})),
            'symbol_list': symbols[:20] if len(symbols) > 20 else symbols,  # ì²˜ìŒ 20ê°œë§Œ í‘œì‹œ
            'truncated': len(symbols) > 20
        },
        'strategy_description': {
            'name': 'Unified Multi-Agent Strategy',
            'type': 'Technical Analysis Based',
            'indicators_used': ['RSI', 'MACD', 'Bollinger Bands', 'Volume'],
            'rebalancing_frequency': 'Daily',
            'risk_management': 'Portfolio-based position sizing with stop-loss'
        },
        'initial_settings': {
            'initial_capital': f"${config.get('initial_cash', 100) * 1000000:,.2f}",
            'max_positions': config.get('max_positions', 10),
            'risk_per_trade': f"{config.get('risk_management', {}).get('max_portfolio_risk', 0.05) * 100:.1f}%",
            'slippage_assumption': f"{config.get('slippage', 0.002) * 100:.2f}%"
        }
    }

    # Performance Summary
    performance_summary = results.get('performance_summary', {})

    # Financial Metrics ê³„ì‚°
    daily_returns = results.get('daily_returns', [])
    if daily_returns:
        daily_returns_array = np.array(daily_returns)
        risk_free_rate = 0.02  # 2% ì—° ë¬´ìœ„í—˜ ìˆ˜ìµë¥  ê°€ì •

        excess_returns = daily_returns_array - (risk_free_rate / 252)  # ì¼ ë¬´ìœ„í—˜ ìˆ˜ìµë¥ 
        sharpe_ratio = np.mean(excess_returns) / np.std(daily_returns_array) * np.sqrt(252) if np.std(daily_returns_array) > 0 else 0

        # Sortino Ratio (í•˜ë°© ìœ„í—˜ ê¸°ì¤€)
        downside_returns = daily_returns_array[daily_returns_array < 0]
        downside_deviation = np.std(downside_returns) if len(downside_returns) > 0 else 0
        sortino_ratio = np.mean(excess_returns) / downside_deviation * np.sqrt(252) if downside_deviation > 0 else 0

        # Calmar Ratio
        max_drawdown = results.get('max_drawdown', 0)
        annual_return = results.get('total_return', 0) * (252 / len(daily_returns)) if len(daily_returns) > 0 else 0
        calmar_ratio = annual_return / abs(max_drawdown) if max_drawdown != 0 else 0

        financial_metrics = {
            'returns': {
                'total_return': f"{results.get('total_return', 0):.2f}%",
                'annualized_return': f"{annual_return:.2f}%",
                'volatility': f"{np.std(daily_returns_array) * np.sqrt(252) * 100:.2f}%",
                'best_day': f"{np.max(daily_returns_array) * 100:.2f}%",
                'worst_day': f"{np.min(daily_returns_array) * 100:.2f}%"
            },
            'risk_metrics': {
                'max_drawdown': f"{max_drawdown:.2f}%",
                'sharpe_ratio': f"{sharpe_ratio:.3f}",
                'sortino_ratio': f"{sortino_ratio:.3f}",
                'calmar_ratio': f"{calmar_ratio:.3f}",
                'value_at_risk_95': f"{np.percentile(daily_returns_array, 5) * 100:.2f}%"
            },
            'trading_metrics': {
                'total_trades': results.get('total_trades', 0),
                'winning_trades': results.get('winning_trades', 0),
                'losing_trades': results.get('losing_trades', 0),
                'win_rate': f"{results.get('win_rate', 0):.1f}%",
                'average_win': f"{results.get('avg_win', 0):.2f}%",
                'average_loss': f"{results.get('avg_loss', 0):.2f}%",
                'profit_factor': f"{results.get('profit_factor', 0):.2f}"
            }
        }
    else:
        financial_metrics = {'error': 'No daily returns data available'}

    # í¬ê´„ì ì¸ ë³´ê³ ì„œ êµ¬ì„±
    comprehensive_report = {
        'overview': overview,
        'performance_summary': performance_summary,
        'financial_metrics': financial_metrics,
        'daily_performance': results.get('daily_performance', []),
        'trade_history': results.get('trade_history', []),
        'symbol_performance': results.get('symbol_performance', {}),
        'drawdown_analysis': results.get('drawdown_analysis', {}),
        'raw_results': results  # ì›ë³¸ ê²°ê³¼ë„ í¬í•¨
    }

    return comprehensive_report

async def run_backtest_mode(config: dict, start_date: str, end_date: str, symbols: list = None):
    """ë°±í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹¤í–‰"""
    try:
        logger.info("=== ë°±í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹œì‘ ===")

        # ë°±í…ŒìŠ¤íŠ¸ ëŒ€ìƒ ì¢…ëª© ê²°ì •
        backtest_symbols = await get_backtest_symbols_from_config(config, symbols)

        logger.info(f"ğŸ“… ë°±í…ŒìŠ¤íŠ¸ ê¸°ê°„: {start_date} ~ {end_date}")
        logger.info(f"[SYMBOLS] ëŒ€ìƒ ì¢…ëª©: {len(backtest_symbols)}ê°œ")

        # ë°±í…ŒìŠ¤íŠ¸ ì—”ì§„ ì„¤ì •
        backtest_config = BacktestEngineConfig(
            timeframe=TimeFrame.DAILY,
            mode=BacktestMode.SINGLE,
            initial_cash=config.get('initial_cash', 100.0),  # 1ì–µì›
            max_positions=config.get('max_positions', 10),
            slippage=config.get('slippage', 0.002),
            std_risk=config['risk_management'].get('max_portfolio_risk', 0.05),
            market='US',
            area='US'
        )

        # ë°±í…ŒìŠ¤íŠ¸ ì—”ì§„ ì´ˆê¸°í™”
        backtest_engine = BacktestEngine(backtest_config)

        # Strategy Integration Service ìƒì„±
        strategy_service = StrategyIntegrationService(
            area='US',
            std_risk=config['risk_management'].get('max_portfolio_risk', 0.05)
        )

        # ì •êµí•œ ë°±í…ŒìŠ¤íŠ¸ ì—”ì§„ ì‚¬ìš©
        logger.info("[START] ì •êµí•œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        results = await run_sophisticated_backtest_engine(
            symbols=backtest_symbols,
            start_date=start_date,
            end_date=end_date,
            initial_cash=config.get('initial_cash', 100.0),
            market_config=config
        )

        if results:
            logger.info("[OK] ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

            # í¬ê´„ì ì¸ ë³´ê³ ì„œ ìƒì„±
            logger.info("[REPORT] í¬ê´„ì ì¸ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
            comprehensive_report = await create_comprehensive_backtest_report(
                results, config, backtest_symbols, start_date, end_date
            )

            # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
            logger.info("=== ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ===")
            financial_metrics = comprehensive_report.get('financial_metrics', {})
            if 'returns' in financial_metrics:
                logger.info(f"[RESULT] ì´ ìˆ˜ìµë¥ : {financial_metrics['returns']['total_return']}")
                logger.info(f"[RESULT] ì—°í™˜ì‚° ìˆ˜ìµë¥ : {financial_metrics['returns']['annualized_return']}")
                logger.info(f"[RESULT] ìµœì¢… ìì‚°: ${results.get('final_value', 0):,.2f}")
                logger.info(f"ğŸ“‰ ìµœëŒ€ ë‚™í­: {financial_metrics['risk_metrics']['max_drawdown']}")
                logger.info(f"âš¡ ìƒ¤í”„ ì§€ìˆ˜: {financial_metrics['risk_metrics']['sharpe_ratio']}")
                logger.info(f"[RESULT] ì´ ê±°ë˜: {financial_metrics['trading_metrics']['total_trades']}")
                logger.info(f"ğŸ† ìŠ¹ë¥ : {financial_metrics['trading_metrics']['win_rate']}")

            # Report/Backtest í´ë”ì— ì €ì¥
            import os
            os.makedirs('Report/Backtest', exist_ok=True)

            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            results_file = f"Report/Backtest/backtest_report_{timestamp}.yaml"

            with open(results_file, 'w', encoding='utf-8') as f:
                yaml.dump(comprehensive_report, f, allow_unicode=True, default_flow_style=False)

            logger.info(f"ğŸ“ í¬ê´„ì ì¸ ë³´ê³ ì„œ ì €ì¥: {results_file}")

            # ìš”ì•½ ì •ë³´ë„ ë³„ë„ ì €ì¥
            summary_file = f"Report/Backtest/summary_{timestamp}.yaml"
            summary = {
                'overview': comprehensive_report['overview'],
                'financial_metrics': comprehensive_report['financial_metrics']
            }
            with open(summary_file, 'w', encoding='utf-8') as f:
                yaml.dump(summary, f, allow_unicode=True, default_flow_style=False)

            logger.info(f"ğŸ“‹ ìš”ì•½ ë³´ê³ ì„œ ì €ì¥: {summary_file}")

        else:
            logger.warning("[WARNING] ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        logger.error(f"ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

def interactive_mode_selection():
    """ëŒ€í™”í˜• ëª¨ë“œ ì„ íƒ"""
    print("\n" + "="*60)
    print("[AI] AI Assistant Multi-Agent Trading System")
    print("="*60)
    print("\nëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("1  ì‹¤ì‹œê°„ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ")
    print("2  ë°±í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ")
    print("3  ì¢…ë£Œ")
    print("-"*60)

    while True:
        try:
            choice = input("\nì„ íƒ (1-3): ").strip()

            if choice == '1':
                print("\n[OK] ì‹¤ì‹œê°„ íŠ¸ë ˆì´ë”© ëª¨ë“œ ì„ íƒë¨")
                return 'TRADING', {}

            elif choice == '2':
                print("\n[OK] ë°±í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì„ íƒë¨")
                return 'BACKTEST', get_backtest_settings()

            elif choice == '3':
                print("\n[EXIT] í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                exit(0)

            else:
                print("[WARNING] ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 1, 2, ë˜ëŠ” 3ì„ ì…ë ¥í•˜ì„¸ìš”.")

        except KeyboardInterrupt:
            print("\n\n[EXIT] í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            exit(0)
        except Exception as e:
            print(f"[ERROR] ì…ë ¥ ì˜¤ë¥˜: {e}")

def get_backtest_settings():
    """ë°±í…ŒìŠ¤íŠ¸ ì„¤ì • ì…ë ¥ ë°›ê¸°"""
    settings = {}

    print("\n[SETUP] ë°±í…ŒìŠ¤íŠ¸ ì„¤ì •")
    print("-"*40)

    # ê¸°ê°„ ì„¤ì •
    print("\n[DATE] ë°±í…ŒìŠ¤íŠ¸ ê¸°ê°„ ì„¤ì •:")
    while True:
        try:
            start_date = input("ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD, ê¸°ë³¸: 2023-01-01): ").strip()
            if not start_date:
                start_date = '2023-01-01'

            # ë‚ ì§œ í˜•ì‹ ê²€ì¦
            from datetime import datetime
            datetime.strptime(start_date, '%Y-%m-%d')
            settings['start_date'] = start_date
            break
        except ValueError:
            print("[ERROR] ì˜¬ë°”ë¥¸ ë‚ ì§œ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš”.")

    while True:
        try:
            end_date = input("ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD, ê¸°ë³¸: 2024-01-01): ").strip()
            if not end_date:
                end_date = '2024-01-01'

            # ë‚ ì§œ í˜•ì‹ ê²€ì¦
            datetime.strptime(end_date, '%Y-%m-%d')
            settings['end_date'] = end_date
            break
        except ValueError:
            print("[ERROR] ì˜¬ë°”ë¥¸ ë‚ ì§œ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš”.")

    # ì´ˆê¸° ìë³¸ ì„¤ì •
    print("\n[CAPITAL] ì´ˆê¸° ìë³¸ ì„¤ì •:")
    while True:
        try:
            initial_cash = input("ì´ˆê¸° ìë³¸ (ë°±ë§Œì› ë‹¨ìœ„, ê¸°ë³¸: 100 = 1ì–µì›): ").strip()
            if not initial_cash:
                initial_cash = 100.0
            else:
                initial_cash = float(initial_cash)
            settings['initial_cash'] = initial_cash
            break
        except ValueError:
            print("[ERROR] ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

    # ì¢…ëª© ì„ íƒ ì„¤ì •
    print("\n[SYMBOLS] ì¢…ëª© ì„ íƒ:")
    print("1. ì „ì²´ ì¢…ëª© (myStockInfo.yaml ì„¤ì •ì— ë”°ë¦„)")
    print("2. íŠ¹ì • ì¢…ëª© ì§ì ‘ ì…ë ¥")

    while True:
        symbol_choice = input("ì„ íƒ (1-2, ê¸°ë³¸: 1): ").strip()
        if not symbol_choice:
            symbol_choice = '1'

        if symbol_choice == '1':
            settings['symbols'] = None
            print("[OK] ì „ì²´ ì¢…ëª© ëª¨ë“œ (ì„¤ì •íŒŒì¼ ë”°ë¦„)")
            break
        elif symbol_choice == '2':
            symbols_input = input("ì¢…ëª© ì½”ë“œë“¤ (ì½¤ë§ˆë¡œ êµ¬ë¶„, ì˜ˆ: AAPL,MSFT,GOOGL): ").strip()
            if symbols_input:
                settings['symbols'] = [s.strip() for s in symbols_input.split(',')]
                print(f"[OK] ì„ íƒëœ ì¢…ëª©: {len(settings['symbols'])}ê°œ")
            else:
                settings['symbols'] = None
                print("[OK] ì…ë ¥ì´ ì—†ì–´ ì „ì²´ ì¢…ëª© ëª¨ë“œë¡œ ì„¤ì •")
            break
        else:
            print("[ERROR] 1 ë˜ëŠ” 2ë¥¼ ì„ íƒí•˜ì„¸ìš”.")

    # ì„¤ì • í™•ì¸
    print("\n[CONFIRM] ë°±í…ŒìŠ¤íŠ¸ ì„¤ì • í™•ì¸:")
    print(f"  [DATE] ê¸°ê°„: {settings['start_date']} ~ {settings['end_date']}")
    print(f"  [CAPITAL] ì´ˆê¸° ìë³¸: {settings['initial_cash']}ë°±ë§Œì›")
    if settings['symbols']:
        print(f"  [SYMBOLS] ëŒ€ìƒ ì¢…ëª©: {len(settings['symbols'])}ê°œ (ì‚¬ìš©ì ì§€ì •)")
    else:
        print(f"  [SYMBOLS] ëŒ€ìƒ ì¢…ëª©: ì „ì²´ ì¢…ëª© (ì„¤ì •íŒŒì¼ ë”°ë¦„)")

    confirm = input("\nê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (Y/n): ").strip().lower()
    if confirm in ['n', 'no']:
        print("[CANCEL] ë°±í…ŒìŠ¤íŠ¸ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return get_backtest_settings()  # ë‹¤ì‹œ ì„¤ì • ì…ë ¥

    return settings

def parse_arguments():
    """ëª…ë ¹í–‰ ì¸ì íŒŒì‹±"""
    parser = argparse.ArgumentParser(
        description='AI Assistant Multi-Agent Trading System',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ì‚¬ìš© ì˜ˆì‹œ:
  # ëŒ€í™”í˜• ëª¨ë“œ (ê¸°ë³¸)
  python main_auto_trade.py

  # ëª…ë ¹í–‰ìœ¼ë¡œ ì‹¤ì‹œê°„ íŠ¸ë ˆì´ë”©
  python main_auto_trade.py --mode TRADING

  # ëª…ë ¹í–‰ìœ¼ë¡œ ë°±í…ŒìŠ¤íŠ¸
  python main_auto_trade.py --mode BACKTEST --start-date 2023-01-01 --end-date 2024-01-01

  # íŠ¹ì • ì¢…ëª©ìœ¼ë¡œ ë°±í…ŒìŠ¤íŠ¸
  python main_auto_trade.py --mode BACKTEST --symbols AAPL,MSFT,GOOGL --start-date 2023-01-01 --end-date 2024-01-01

ê²°ê³¼ ì €ì¥:
  - í¬ê´„ì ì¸ ë³´ê³ ì„œ: Report/Backtest/backtest_report_YYYYMMDD_HHMMSS.yaml
  - ìš”ì•½ ë³´ê³ ì„œ: Report/Backtest/summary_YYYYMMDD_HHMMSS.yaml
        '''
    )

    parser.add_argument(
        '--mode',
        choices=['TRADING', 'BACKTEST', 'INTERACTIVE'],
        default='INTERACTIVE',
        help='ì‹œìŠ¤í…œ ëª¨ë“œ (ê¸°ë³¸: INTERACTIVE - ëŒ€í™”í˜• ì„ íƒ)'
    )

    parser.add_argument(
        '--start-date',
        type=str,
        default='2023-01-01',
        help='ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD, ê¸°ë³¸: 2023-01-01)'
    )

    parser.add_argument(
        '--end-date',
        type=str,
        default='2024-01-01',
        help='ë°±í…ŒìŠ¤íŠ¸ ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD, ê¸°ë³¸: 2024-01-01)'
    )

    parser.add_argument(
        '--symbols',
        type=str,
        default=None,
        help='ëŒ€ìƒ ì¢…ëª© (ì½¤ë§ˆë¡œ êµ¬ë¶„, ê¸°ë³¸: myStockInfo.yaml ì„¤ì •ì— ë”°ë¼ ì „ì¢…ëª© ë˜ëŠ” ìƒ˜í”Œ)'
    )

    parser.add_argument(
        '--config',
        type=str,
        default='myStockInfo.yaml',
        help='ì„¤ì • íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸: myStockInfo.yaml)'
    )

    parser.add_argument(
        '--initial-cash',
        type=float,
        default=100.0,
        help='ë°±í…ŒìŠ¤íŠ¸ ì´ˆê¸° ìë³¸ (ë°±ë§Œì› ë‹¨ìœ„, ê¸°ë³¸: 100 = 1ì–µì›)'
    )

    return parser.parse_args()

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # ëª…ë ¹í–‰ ì¸ì íŒŒì‹±
        args = parse_arguments()

        # ëŒ€í™”í˜• ëª¨ë“œì¸ ê²½ìš° ì‚¬ìš©ì ì„ íƒ ë°›ê¸°
        if args.mode == 'INTERACTIVE':
            mode, interactive_settings = interactive_mode_selection()

            # ëŒ€í™”í˜•ìœ¼ë¡œ ë°›ì€ ì„¤ì •ì„ argsì— ë³‘í•©
            if mode == 'BACKTEST':
                args.mode = 'BACKTEST'
                args.start_date = interactive_settings['start_date']
                args.end_date = interactive_settings['end_date']
                args.initial_cash = interactive_settings['initial_cash']
                if interactive_settings['symbols']:
                    args.symbols = ','.join(interactive_settings['symbols'])
                else:
                    args.symbols = None

        logger.info("=== AI Assistant Multi-Agent Trading System ===")
        logger.info(f"ğŸ”§ ì‹¤í–‰ ëª¨ë“œ: {args.mode}")

        if args.mode == 'BACKTEST':
            logger.info(f"ğŸ“… ë°±í…ŒìŠ¤íŠ¸ ê¸°ê°„: {args.start_date} ~ {args.end_date}")
            if args.symbols:
                logger.info(f"[SYMBOLS] ëŒ€ìƒ ì¢…ëª©: {len(args.symbols.split(','))}ê°œ (ì‚¬ìš©ì ì§€ì •)")
            else:
                logger.info("[SYMBOLS] ëŒ€ìƒ ì¢…ëª©: ì „ì²´ ì¢…ëª© (ì„¤ì •íŒŒì¼ ë”°ë¦„)")
            logger.info(f"[CAPITAL] ì´ˆê¸° ìë³¸: {args.initial_cash}ë°±ë§Œì›")

        logger.info(f"âš™ï¸ ì„¤ì • íŒŒì¼: {args.config}")

        # 1. ì„¤ì • ë¡œë“œ
        config = load_config()
        if not config:
            logger.error("ì„¤ì • ë¡œë“œ ì‹¤íŒ¨ - í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
            return

        # ì¸ìì—ì„œ ë°›ì€ ì„¤ì • ì¶”ê°€
        config['initial_cash'] = args.initial_cash

        # ë°±í…ŒìŠ¤íŠ¸ ëª¨ë“œ ë¶„ê¸°
        if args.mode == 'BACKTEST':
            print("\n" + "="*60)
            print("[START] ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘")
            print("="*60)

            symbols_list = None
            if args.symbols:
                symbols_list = [s.strip() for s in args.symbols.split(',')]
                logger.info(f"[SYMBOLS] ì‚¬ìš©ì ì§€ì • ì¢…ëª©: {len(symbols_list)}ê°œ")
            else:
                logger.info("[SYMBOLS] myStockInfo.yaml ì„¤ì •ì— ë”°ë¥¸ ì¢…ëª© ì„ íƒ")

            await run_backtest_mode(config, args.start_date, args.end_date, symbols_list)
            return

        elif args.mode == 'TRADING':
            print("\n" + "="*60)
            print("[START] ì‹¤ì‹œê°„ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ ì‹œì‘")
            print("="*60)

        # 2. Strategy Integration Service ìƒì„± (US ë§ˆì¼“ìš©)
        logger.info("Strategy Integration Service ì´ˆê¸°í™” ì¤‘... (US ë§ˆì¼“)")
        strategy_service = StrategyIntegrationService(
            area='US',  # ëª…ì‹œì ìœ¼ë¡œ US ë§ˆì¼“ ì„¤ì •
            std_risk=config['risk_management'].get('max_portfolio_risk', 0.05)
        )

        # 3. ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìƒì„±
        logger.info("ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™” ì¤‘...")
        orchestrator = None
        try:
            orchestrator = AutoTradeOrchestrator(config)
        except Exception as e:
            logger.error(f"ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return

        # 4. ì´ë²¤íŠ¸ ì½œë°± ë“±ë¡
        events_log = []

        async def log_events(event_data):
            events_log.append(event_data)
            event_type = type(event_data.get('signal', event_data.get('alert', {}))).__name__
            symbol = getattr(event_data.get('signal'), 'symbol', 'SYSTEM')
            logger.info(f"[ì´ë²¤íŠ¸] {symbol}: {event_type}")

        # ì£¼ìš” ì´ë²¤íŠ¸ ì½œë°± ë“±ë¡
        orchestrator.register_event_callback('signal_received', log_events)
        orchestrator.register_event_callback('order_executed', log_events)
        orchestrator.register_event_callback('risk_alert', log_events)

        # 5. ì‹œìŠ¤í…œ ì‹œì‘
        logger.info("ì „ì²´ ì‹œìŠ¤í…œ ì‹œì‘ ì¤‘...")
        system_started = await orchestrator.start_system()

        if not system_started:
            logger.error("ì‹œìŠ¤í…œ ì‹œì‘ ì‹¤íŒ¨ - í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
            return

        logger.info("[OK] ì‹œìŠ¤í…œ ì‹œì‘ ì™„ë£Œ")

        # 6. ê±°ë˜ í™œì„±í™”
        logger.info("ìë™ ê±°ë˜ í™œì„±í™” ì¤‘...")
        trading_enabled = await orchestrator.enable_trading()

        if trading_enabled:
            logger.info("[OK] ìë™ ê±°ë˜ í™œì„±í™” ì™„ë£Œ")
        else:
            logger.warning("[WARNING] ê±°ë˜ í™œì„±í™” ì‹¤íŒ¨ - ëª¨ë‹ˆí„°ë§ë§Œ ì‹¤í–‰")

        # 7. ì‹¤ì œ Strategy Layerì—ì„œ ì‹ í˜¸ ìƒì„±
        logger.info("=== ì‹¤ì œ Strategy Layer ì‹ í˜¸ ìƒì„± í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ===")
        real_signals, account_data = await generate_real_trading_signals(orchestrator, strategy_service)

        # 8. ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì— ì‹¤ì œ ê³„ì¢Œ ë°ì´í„° ì„¤ì •
        if account_data:
            await orchestrator.set_real_account_data(account_data)
            logger.info("[OK] ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì— ì‹¤ì œ ê³„ì¢Œ ë°ì´í„° ì„¤ì • ì™„ë£Œ")

        # ì‹¤ì œ ë³´ìœ /í›„ë³´ ì¢…ëª© ê¸°ë°˜ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì„¤ì •
        await setup_real_time_monitoring(orchestrator, account_data, real_signals)

        # 3ë‹¨ê³„ê°€ ëª¨ë‘ ì™„ë£Œëœ í›„ì—ë§Œ ë‹¤ìŒ ì‘ì—… ì§„í–‰
        logger.info("=== Strategy Layer ì‹ í˜¸ ìƒì„± í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ - ì‹ í˜¸ ì²˜ë¦¬ ì‹œì‘ ===")

        if real_signals:
            logger.info(f"ì²˜ë¦¬í•  ì‹ í˜¸ ê°œìˆ˜: {len(real_signals)}ê°œ")
            for signal in real_signals:
                success = await orchestrator.add_trading_signal(signal)
                if success:
                    logger.info(f"[SIGNAL] Strategy ì‹ í˜¸ ì¶”ê°€: {signal.symbol} {signal.signal_type.value} (ì‹ ë¢°ë„: {signal.confidence:.2f})")

                # ì‹ í˜¸ ê°„ ê°„ê²©
                await asyncio.sleep(2)
        else:
            logger.info("ìƒì„±ëœ ì‹ í˜¸ê°€ ì—†ìŠµë‹ˆë‹¤ - ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ëª¨ë“œë¡œ ì§„í–‰")

        # 8. ì‹ í˜¸ ì²˜ë¦¬ ì™„ë£Œ í›„ ì‹¤ì‹œê°„ ë””ìŠ¤í”Œë ˆì´ ì‹œì‘
        logger.info("[OK] ì‹ í˜¸ ì²˜ë¦¬ ì™„ë£Œ - ì‹¤ì‹œê°„ ë””ìŠ¤í”Œë ˆì´ ì‹œì‘")
        await orchestrator.start_realtime_display()

        # 9. ì‹œìŠ¤í…œ ìš´ì˜
        logger.info("ğŸš€ ìë™ë§¤ë§¤ ì‹œìŠ¤í…œ ìš´ì˜ ì‹œì‘")
        logger.info("[MONITOR] Real time monitor í™œì„±í™”ë¨")
        logger.info("ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”...")

        # Real time monitoring ë¹„í™œì„±í™” - ê°„ë‹¨í•œ ëŒ€ê¸° ë£¨í”„ë¡œ ë³€ê²½
        try:
            while True:
                # ë‹¨ìˆœíˆ ëŒ€ê¸°ë§Œ í•˜ê³  ì£¼ê¸°ì  ìƒíƒœ ì¶œë ¥ ë¹„í™œì„±í™”
                await asyncio.sleep(10)  # 10ì´ˆë§ˆë‹¤ ì²´í¬ (ìƒíƒœ ì¶œë ¥ ì—†ìŒ)

        except KeyboardInterrupt:
            logger.info("\nğŸ‘‹ ì‚¬ìš©ì ì¤‘ë‹¨ ìš”ì²­ ê°ì§€")
        except Exception as e:
            logger.error(f"ìš´ì˜ ì¤‘ ì˜¤ë¥˜: {e}")

        # # ê¸°ì¡´ Real time monitor ì½”ë“œ (ì£¼ì„ ì²˜ë¦¬)
        # # ì£¼ê¸°ì  ìƒíƒœ ì¶œë ¥
        # status_interval = 30  # 30ì´ˆë§ˆë‹¤ ìƒíƒœ ì¶œë ¥
        # last_status_time = datetime.now()
        #
        # while True:
        #     try:
        #         # 30ì´ˆë§ˆë‹¤ ì‹œìŠ¤í…œ ìƒíƒœ ì¶œë ¥
        #         current_time = datetime.now()
        #         if (current_time - last_status_time).seconds >= status_interval:
        #
        #             # ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ
        #             system_status = await orchestrator.get_system_status()
        #             trading_summary = await orchestrator.get_trading_summary()
        #
        #             logger.info("=" * 60)
        #             logger.info(f"ğŸ“ˆ ì‹œìŠ¤í…œ ìƒíƒœ: {current_time.strftime('%H:%M:%S')}")
        #             logger.info(f"   ì‹¤í–‰ìƒíƒœ: {system_status.get('is_running')}")
        #             logger.info(f"   ê±°ë˜í™œì„±: {system_status.get('is_trading_active')}")
        #             logger.info(f"   ì²˜ë¦¬ì‹ í˜¸: {system_status.get('total_signals_processed')}ê°œ")
        #             logger.info(f"   ì‹¤í–‰ì£¼ë¬¸: {system_status.get('total_orders_executed')}ê°œ")
        #
        #             # í˜„ì¬ ì‹ í˜¸ ìƒíƒœ
        #             signals_info = trading_summary.get('signals', {})
        #             logger.info(f"   í˜„ì¬ì‹ í˜¸: {signals_info.get('current_count', 0)}ê°œ")
        #
        #             # í¬íŠ¸í´ë¦¬ì˜¤ ìƒíƒœ
        #             portfolio_info = trading_summary.get('portfolio', {})
        #             total_value = portfolio_info.get('total_value', 0)
        #             day_pnl = portfolio_info.get('day_pnl', 0)
        #             day_pnl_pct = portfolio_info.get('day_pnl_pct', 0)
        #
        #             if total_value > 0:
        #                 logger.info(f"   í¬íŠ¸í´ë¦¬ì˜¤: ${total_value:,.0f}")
        #                 pnl_color = "ğŸŸ¢" if day_pnl >= 0 else "ğŸ”´"
        #                 logger.info(f"   ì¼ì¼ì†ìµ: {pnl_color} ${day_pnl:+,.0f} ({day_pnl_pct:+.2f}%)")
        #
        #             # ë¦¬ìŠ¤í¬ ìƒíƒœ
        #             risk_info = trading_summary.get('risk', {})
        #             risk_level = risk_info.get('level', 'UNKNOWN')
        #             active_alerts = risk_info.get('active_alerts', 0)
        #
        #             risk_emoji = "ğŸŸ¢" if risk_level == 'NORMAL' else "ğŸŸ¡" if risk_level == 'WARNING' else "ğŸ”´"
        #             logger.info(f"   ë¦¬ìŠ¤í¬ìƒíƒœ: {risk_emoji} {risk_level}")
        #
        #             if active_alerts > 0:
        #                 logger.info(f"   í™œì„±ì•Œë¦¼: {active_alerts}ê°œ")
        #
        #             logger.info("=" * 60)
        #
        #             last_status_time = current_time
        #
        #         # 1ì´ˆ ëŒ€ê¸°
        #         await asyncio.sleep(1)
        #
        #     except KeyboardInterrupt:
        #         logger.info("\nğŸ‘‹ ì‚¬ìš©ì ì¤‘ë‹¨ ìš”ì²­ ê°ì§€")
        #         break
        #     except Exception as e:
        #         logger.error(f"ìš´ì˜ ì¤‘ ì˜¤ë¥˜: {e}")
        #         await asyncio.sleep(5)

    except KeyboardInterrupt:
        logger.info("\nğŸ‘‹ í”„ë¡œê·¸ë¨ ì¤‘ë‹¨ ìš”ì²­")
    except Exception as e:
        logger.error(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # 9. ì‹œìŠ¤í…œ ì¢…ë£Œ
        logger.info("ğŸ›‘ ì‹œìŠ¤í…œ ì¢…ë£Œ ì¤‘...")
        try:
            # orchestratorê°€ ì •ì˜ë˜ì–´ ìˆê³  Noneì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì¢…ë£Œ
            if 'orchestrator' in locals() and orchestrator is not None:
                await orchestrator.stop_system()
                logger.info("[OK] ì‹œìŠ¤í…œ ì •ìƒ ì¢…ë£Œ ì™„ë£Œ")
            else:
                logger.info("[OK] ë°±í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì¢…ë£Œ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ì‹œìŠ¤í…œ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {e}")

        logger.info("=== ìë™ë§¤ë§¤ ì‹œìŠ¤í…œ ì¢…ë£Œ ===")

def load_fundamental_data_from_refer(df, symbol, nasdaq_db, nyse_db):
    """ê¸°ë³¸ í€ë”ë©˜í„¸ ë°ì´í„° ìƒì„±"""
    try:
        # ê¸°ë³¸ í€ë”ë©˜í„¸ ë°ì´í„° ìƒì„±
        estimated_shares = 1000000000  # 10ì–µì£¼ë¡œ ê°€ì •
        df['MarketCapitalization'] = df['close'] * estimated_shares

        # ê¸°ë³¸ ì„±ì¥ë¥  ì„¤ì •
        symbol_hash = hash(symbol) % 10000
        np.random.seed(symbol_hash)

        base_rev_growth = np.random.uniform(0.05, 0.25)  # 5-25% ê¸°ë³¸ ì„±ì¥ë¥ 
        base_eps_growth = np.random.uniform(0.05, 0.25)  # 5-25% ê¸°ë³¸ ì„±ì¥ë¥ 

        df['REV_YOY'] = base_rev_growth + np.random.uniform(-0.05, 0.05, len(df))
        df['EPS_YOY'] = base_eps_growth + np.random.uniform(-0.05, 0.05, len(df))
        df['revenue'] = 1000000000  # 10ì–µ ë‹¬ëŸ¬ë¡œ ê°€ì •

        return df

    except Exception as e:
        logger.error(f"í€ë”ë©˜í„¸ ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’ ì„¤ì •
        df['REV_YOY'] = 0.1
        df['EPS_YOY'] = 0.1
        df['revenue'] = 1000000000
        df['MarketCapitalization'] = 2000000000  # 20ì–µ ë‹¬ëŸ¬
        return df

def generate_sophisticated_signals(df, symbol):
    """refer Style ì •êµí•œ ì‹ í˜¸ ìƒì„± ë¡œì§ - ì™„ì „í•œ ì¬êµ¬í˜„"""
    try:
        # 1. ê¸°ë³¸ ì»¬ëŸ¼ ì´ˆê¸°í™”
        df['BuySig'] = 0
        df['SellSig'] = 0
        df['signal'] = 0
        df['wBuySig'] = 0
        df['dBuySig'] = 0
        df['rsBuySig'] = 0
        df['fBuySig'] = 0
        df['eBuySig'] = 0
        df['Type'] = None

        # 2. refer Strategy_Aì˜ ëª¨ë“  í•„ìˆ˜ ì§€í‘œ ê³„ì‚°
        df = calculate_comprehensive_indicators(df, symbol)

        # 3. refer Strategy_Aì˜ ì •í™•í•œ ì‹ í˜¸ ìƒì„± ìˆœì„œ
        df = generate_rs_signal_exact(df, symbol)          # RS ì‹ í˜¸ (refer ë¡œì§)
        df = generate_weekly_signal_exact(df, symbol)      # ì£¼ê°„ ì‹ í˜¸ (refer ë¡œì§)
        df = generate_fundamental_signal_exact(df, symbol) # í€ë”ë©˜í„¸ ì‹ í˜¸ (refer ë¡œì§)
        df = generate_earnings_signal_exact(df, symbol)    # ìˆ˜ìµ ì‹ í˜¸ (refer ë¡œì§)
        df = generate_daily_signal_exact(df, symbol)       # ì¼ê°„ ì‹ í˜¸ (refer ë¡œì§)

        # 4. refer Strategy_Aì˜ ì •í™•í•œ ìµœì¢… í†µí•© ì‹ í˜¸ ìƒì„±
        # lines 465-466: Buy_conditions = [Ent_Cond1 & (Ent_Cond2) & Ent_Cond3 & Ent_Cond4]
        ent_cond1 = df['wBuySig'] == 1   # ì£¼ê°„ ì¡°ê±´
        ent_cond2 = df['dBuySig'] == 1   # ì¼ê°„ ì¡°ê±´
        ent_cond3 = df['rsBuySig'] == 1  # RS ì¡°ê±´
        ent_cond4 = df['fBuySig'] == 1   # í€ë”ë©˜í„¸ ì¡°ê±´

        # US ë§ˆì¼“ ì¡°ê±´ (refer ì •í™•í•œ ë¶„ì„ ë°˜ì˜)
        # ì‚¬ìš©ì í™•ì¸ ê²°ê³¼: w, d, rs, f ì¡°ê±´ ëª¨ë‘ ì‚¬ìš©, e ì¡°ê±´ë§Œ ì œì™¸
        # refer Strategy_A.py line 466: Buy_conditions = [Ent_Cond1 & (Ent_Cond2) & Ent_Cond3 & Ent_Cond4]

        # ìµœì¢… ì‹ í˜¸ ì¡°ê±´: w & d & rs & f (e ì¡°ê±´ ì œì™¸)
        buy_condition = ent_cond1 & ent_cond2 & ent_cond3 & ent_cond4  # w & d & rs & f

        df.loc[buy_condition, 'BuySig'] = 1

        # ë””ë²„ê¹…: ê° ì¡°ê±´ë³„ í†µê³¼ ê°œìˆ˜ í™•ì¸
        w_pass = ent_cond1.sum()
        d_pass = ent_cond2.sum()
        rs_pass = ent_cond3.sum()
        f_pass = ent_cond4.sum()

        # ì¡°í•©ë³„ í†µê³¼ ê°œìˆ˜
        wd_pass = (ent_cond1 & ent_cond2).sum()
        wdr_pass = (ent_cond1 & ent_cond2 & ent_cond3).sum()
        wdrf_pass = buy_condition.sum()

        logger.info(f"[SIGNAL_FILTER] {symbol}: w={w_pass}, d={d_pass}, rs={rs_pass}, f={f_pass}")
        logger.info(f"[SIGNAL_COMBO] {symbol}: w&d={wd_pass}, w&d&rs={wdr_pass}, w&d&rs&f={wdrf_pass}")

        # DEBUG: Check dates where BuySig=1 for backtest period
        buysig_dates = df[df['BuySig'] == 1].index
        # 1ë…„ ë°±í…ŒìŠ¤íŠ¸ ê¸°ê°„ìœ¼ë¡œ ìˆ˜ì • (2022-01-01 ~ 2023-01-31)
        backtest_period_signals = df[(df.index >= '2022-01-01') & (df.index <= '2023-01-31') & (df['BuySig'] == 1)]

        logger.info(f"[SIGNAL_DATES] {symbol}: Total BuySig=1 dates: {len(buysig_dates)}")
        if len(buysig_dates) > 0:
            logger.info(f"[SIGNAL_DATES] {symbol}: First BuySig date: {buysig_dates[0]}")
            logger.info(f"[SIGNAL_DATES] {symbol}: Last BuySig date: {buysig_dates[-1]}")
        logger.info(f"[SIGNAL_DATES] {symbol}: BuySig=1 in backtest period (2022-01 to 2023-01): {len(backtest_period_signals)}")
        if len(backtest_period_signals) > 0:
            logger.info(f"[SIGNAL_DATES] {symbol}: Backtest period BuySig dates: {list(backtest_period_signals.index)}")
        logger.info(f"[SIGNAL_DATES] {symbol}: Data range: {df.index[0]} to {df.index[-1]}")

        # 5. ë§¤ë„ ì‹ í˜¸ ìƒì„± (refer lines 474-479)
        exit_cond1 = df['close'] < df['SMA20']  # referì˜ dSellSig ì¡°ê±´
        df.loc[exit_cond1, 'SellSig'] = 1

        # 6. signal ì»¬ëŸ¼ ìƒì„± (refer lines 482-490)
        cond1 = df['BuySig'] == 1
        cond2 = df['SellSig'] == 0
        signal_condition = cond1 & cond2
        df.loc[signal_condition, 'signal'] = 1

        # 7. ë””ë²„ê¹… ë¡œê·¸ (refer ìŠ¤íƒ€ì¼)
        buy_signals = (df['BuySig'] == 1).sum()
        w_signals = (df['wBuySig'] == 1).sum()
        d_signals = (df['dBuySig'] == 1).sum()
        rs_signals = (df['rsBuySig'] == 1).sum()
        f_signals = (df['fBuySig'] == 1).sum()
        e_signals = (df['eBuySig'] == 1).sum()

        # refer ìŠ¤íƒ€ì¼ ìƒì„¸ ë””ë²„ê¹… (INFO ë ˆë²¨ë¡œ ì¶œë ¥)
        logger.info(f"[SIGNAL_DETAIL] {symbol}: wBuySig={w_signals}, dBuySig={d_signals}, rsBuySig={rs_signals}, fBuySig={f_signals}, eBuySig={e_signals}, Final BuySig={buy_signals}")

        # ë°ì´í„° í¬ê¸° í™•ì¸
        logger.info(f"[DATA_SIZE] {symbol}: DataFrame length={len(df)}, has_data={len(df) > 200}")

        # ì£¼ìš” ì§€í‘œ ìƒ˜í”Œê°’ í™•ì¸ (ë§ˆì§€ë§‰ 5ê°œ ê°’)
        if len(df) > 5:
            logger.info(f"[INDICATORS] {symbol}: RS_4W last 5 values={df['RS_4W'].tail(5).values}")
            logger.info(f"[INDICATORS] {symbol}: MarketCap last 5 values={df['MarketCapitalization'].tail(5).values}")
            logger.info(f"[INDICATORS] {symbol}: SMA200_M last 5 values={df['SMA200_M'].tail(5).values}")

        # ê° ì¡°ê±´ì„ ê°œë³„ì ìœ¼ë¡œ ì²´í¬
        if w_signals == 0 and d_signals == 0 and rs_signals == 0 and f_signals == 0:
            logger.warning(f"[ZERO_SIGNALS] {symbol}: ALL signals are zero - possible data issue")

        return df

    except Exception as e:
        logger.error(f"[SIGNAL] {symbol}: ì‹ í˜¸ ìƒì„± ì‹¤íŒ¨ - {e}")
        # ì‹¤íŒ¨ì‹œ ëª¨ë“  ì‹ í˜¸ë¥¼ 0ìœ¼ë¡œ ì„¤ì •
        for col in ['BuySig', 'SellSig', 'signal', 'wBuySig', 'dBuySig', 'rsBuySig', 'fBuySig', 'eBuySig']:
            if col not in df.columns:
                df[col] = 0
        return df

def calculate_comprehensive_indicators(df, symbol):
    """refer Strategy_Aì— í•„ìš”í•œ ëª¨ë“  ì§€í‘œ ê³„ì‚°"""
    try:
        # 1. ì´ë™í‰ê·  ê³„ì‚° (referê°€ ì‚¬ìš©í•˜ëŠ” ê²ƒë“¤)
        df['SMA20'] = df['close'].rolling(window=20).mean()
        df['SMA50'] = df['close'].rolling(window=50).mean()
        df['SMA200'] = df['close'].rolling(window=200).mean()

        # SMA200 ëª¨ë©˜í…€ ê³„ì‚° (refer line 233)
        df['SMA200_M'] = df['SMA200'].pct_change()

        # 2. ìµœê³ ê°€/ìµœì €ê°€ ê³„ì‚° (refer ì¼ê°„ ì‹ í˜¸ìš©)
        df['Highest_1M'] = df['high'].rolling(window=20).max()    # 1ê°œì›” = 20ì¼
        df['Highest_3M'] = df['high'].rolling(window=60).max()    # 3ê°œì›” = 60ì¼
        df['Highest_6M'] = df['high'].rolling(window=120).max()   # 6ê°œì›” = 120ì¼
        df['Highest_1Y'] = df['high'].rolling(window=252).max()   # 1ë…„ = 252ì¼
        df['Highest_2Y'] = df['high'].rolling(window=504).max()   # 2ë…„ = 504ì¼

        # 3. ì£¼ê°„ ì§€í‘œ (refer ì£¼ê°„ ì‹ í˜¸ìš©)
        # referì™€ ë™ì¼í•˜ê²Œ ì‹¤ì œ ì£¼ê°„ ë°ì´í„°ë¥¼ MongoDBì—ì„œ ë¡œë“œ
        weekly_data = load_weekly_data_from_mongodb(symbol)
        if weekly_data is not None:
            # ì‹¤ì œ ì£¼ê°„ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
            logger.info(f"[WEEKLY_DATA] {symbol}: Using actual weekly data from MongoDB")
            # ì£¼ê°„ ë°ì´í„°ë¥¼ ì¼ê°„ ë°ì´í„°ì™€ ë§ì¶°ì„œ ë³‘í•©
            df = merge_weekly_data_to_daily(df, weekly_data)
        else:
            # ì£¼ê°„ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ê¸°ì¡´ ê·¼ì‚¬ ê³„ì‚° ì‚¬ìš©
            logger.warning(f"[WEEKLY_DATA] {symbol}: No weekly data found, using calculated approximation")
            df['52_H'] = df['high'].rolling(window=252).max()  # 52ì£¼ ê³ ì 
            df['52_L'] = df['low'].rolling(window=252).min()   # 52ì£¼ ì €ì 
            df['1Year_H'] = df['high'].rolling(window=252).max()
            df['2Year_H'] = df['high'].rolling(window=504).max()
            df['1Year_L'] = df['low'].rolling(window=252).min()
            df['2Year_L'] = df['low'].rolling(window=504).min()

            # ì£¼ê°„ ì¢…ê°€ (5ì¼ ì´ë™í‰ê· ìœ¼ë¡œ ê·¼ì‚¬)
            df['Wclose'] = df['close'].rolling(window=5).mean()

        # 4. RS ì§€í‘œ ê³„ì‚° (refer RS ì‹ í˜¸ìš©)
        # referì™€ ë™ì¼í•˜ê²Œ ì‹¤ì œ RS ë°ì´í„°ë¥¼ MongoDBì—ì„œ ë¡œë“œ
        rs_data = load_rs_data_from_mongodb(symbol)
        if rs_data is not None:
            logger.info(f"[RS_DATA] {symbol}: Using actual RS data from MongoDB")
            df = merge_rs_data_to_daily(df, rs_data)
        else:
            logger.warning(f"[RS_DATA] {symbol}: No RS data found, using calculated approximation")
            # RS_4Wë¥¼ ì‹œì¥ ì „ì²´ ëŒ€ë¹„ ìƒëŒ€ê°•ë„ë¡œ ê³„ì‚° (ê°„ëµí™”)
            df['price_change_4w'] = df['close'].pct_change(20)  # 4ì£¼ ìˆ˜ìµë¥ 
        # ìƒëŒ€ê°•ë„ë¥¼ ë°±ë¶„ìœ„ìˆ˜ë¡œ ê³„ì‚° (ê°„ëµí™”: ìì‹ ì˜ ê³¼ê±° ì„±ê³¼ ëŒ€ë¹„)
        df['RS_4W'] = df['price_change_4w'].rolling(window=60).rank(pct=True) * 100

        # 5. í€ë”ë©˜í„¸ ì§€í‘œ (refer í€ë”ë©˜í„¸ ì‹ í˜¸ìš©)
        # referì™€ ë™ì¼í•˜ê²Œ ì‹¤ì œ í€ë”ë©˜í„¸ ë°ì´í„°ë¥¼ MongoDBì—ì„œ ë¡œë“œ
        fundamental_data = load_fundamental_data_from_mongodb(symbol)
        if fundamental_data is not None:
            logger.info(f"[FUNDAMENTAL_DATA] {symbol}: Using actual fundamental data from MongoDB")
            df = merge_fundamental_data_to_daily(df, fundamental_data)
        else:
            logger.warning(f"[FUNDAMENTAL_DATA] {symbol}: No fundamental data found, using calculated approximation")
            # ê¸°ì¡´ approximation ë¡œì§ ì‚¬ìš©
        # ì‹œê°€ì´ì•¡ ê·¼ì‚¬ ê³„ì‚° (ì£¼ê°€ * ê°€ìƒ ë°œí–‰ì£¼ì‹ìˆ˜)
        estimated_shares = 1000000000  # 10ì–µì£¼ë¡œ ê°€ì •
        df['MarketCapitalization'] = df['close'] * estimated_shares

        # ë§¤ì¶œ/EPS ì„±ì¥ë¥  (ì„ì˜ ìƒì„± - ì‹¤ì œë¡œëŠ” APIì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
        # ë°±í…ŒìŠ¤íŠ¸ ì¼ê´€ì„±ì„ ìœ„í•´ ê²°ì •ì  ê°’ ìƒì„±
        import hashlib
        symbol_hash = int(hashlib.md5(str(df.index[0]).encode()).hexdigest()[:8], 16)
        np.random.seed(symbol_hash % 10000)  # ì¢…ëª©ë³„ ê³ ì • ì‹œë“œ

        base_rev_growth = np.random.uniform(0.05, 0.25)  # 5-25% ê¸°ë³¸ ì„±ì¥ë¥ 
        base_eps_growth = np.random.uniform(0.05, 0.25)  # 5-25% ê¸°ë³¸ ì„±ì¥ë¥ 

        df['REV_YOY'] = base_rev_growth + np.random.uniform(-0.05, 0.05, len(df))
        df['EPS_YOY'] = base_eps_growth + np.random.uniform(-0.05, 0.05, len(df))
        df['revenue'] = 1000000000  # 10ì–µ ë‹¬ëŸ¬ë¡œ ê°€ì •

        # 6. ê¸°íƒ€ í•„ìš”í•œ ì§€í‘œë“¤
        df['Dhigh'] = df['high']
        df['Dlow'] = df['low']
        df['Dclose'] = df['close']
        df['Dopen'] = df['open']

        return df

    except Exception as e:
        logger.error(f"ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return df

def calculate_technical_indicators(df):
    """ê¸°ë³¸ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° (í•˜ìœ„ í˜¸í™˜ì„±)"""
    try:
        # ì´ë™í‰ê· 
        df['SMA20'] = df['close'].rolling(window=20).mean()
        df['SMA50'] = df['close'].rolling(window=50).mean()

        # ìµœê³ ê°€/ìµœì €ê°€ ê¸°ê°„ë³„
        df['Highest_1M'] = df['high'].rolling(window=21).max()
        df['Highest_3M'] = df['high'].rolling(window=63).max()
        df['Highest_6M'] = df['high'].rolling(window=126).max()
        df['Highest_1Y'] = df['high'].rolling(window=252).max()
        df['Highest_2Y'] = df['high'].rolling(window=504).max()

        # RS_4Wë¥¼ refer ë°©ì‹ìœ¼ë¡œ ê³„ì‚°: 4ì£¼ ë³€ë™ë¥ ì˜ ë°±ë¶„ìœ„ ìˆœìœ„
        # referì˜ RS_4WëŠ” ì‹œì¥ ì „ì²´ ëŒ€ë¹„ ìƒëŒ€ê°•ë„ë¥¼ 0-100 ë°±ë¶„ìœ„ë¡œ í‘œí˜„
        price_change_4w = ((df['close'] / df['close'].shift(20)) - 1) * 100

        # referì™€ ê°™ì´ ë°±ë¶„ìœ„ ìˆœìœ„ë¡œ ë³€í™˜ (rolling 60ì¼ ìœˆë„ìš° ì‚¬ìš©)
        df['RS_4W'] = price_change_4w.rolling(window=60, min_periods=20).rank(pct=True) * 100
        df['RS_4W'] = df['RS_4W'].fillna(50)  # ê¸°ë³¸ê°’ 50 (ì¤‘ê°„ê°’)

        # Rev_Yoy_Growth, Eps_Yoy_GrowthëŠ” F ì‹ í˜¸ ìƒì„± ì‹œ ê³„ì‚°ë¨

        # ì„¹í„°/ì‚°ì—… ì •ë³´ëŠ” ë¬¸ìì—´ë¡œ ë³„ë„ ì²˜ë¦¬
        if 'Sector' not in df.columns:
            df['Sector'] = 'Technology'
        if 'Industry' not in df.columns:
            df['Industry'] = 'Software'

        return df
    except Exception as e:
        logger.error(f"ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return df

def generate_rs_signal_exact(df, symbol):
    """RS ì‹ í˜¸ ìƒì„± - refer Strategy_A ì •í™•í•œ êµ¬í˜„ (lines 66-89)"""
    try:
        # ë°±í…ŒìŠ¤íŠ¸ ê¸°ê°„ ë‚´ RS_4W ê°’ í†µê³„ í™•ì¸
        backtest_df = df[(df.index >= '2022-01-01') & (df.index <= '2023-01-31')]
        if len(backtest_df) > 0 and 'RS_4W' in backtest_df.columns:
            rs_values = backtest_df['RS_4W']
            rs_min, rs_max, rs_mean = rs_values.min(), rs_values.max(), rs_values.mean()
            above_90 = (rs_values >= 90).sum()
            total = len(rs_values)
            logger.info(f"[RS_DEBUG] {symbol}: RS_4W stats - min={rs_min:.1f}, max={rs_max:.1f}, mean={rs_mean:.1f}")
            logger.info(f"[RS_DEBUG] {symbol}: RS_4W >= 90: {above_90}/{total} ({above_90/total*100:.1f}%)")

        # refer line 73: rsCondition1 = self.df_RS[stocks]['RS_4W'] >= 90
        rs_condition1 = df['RS_4W'] >= 90
        rs_conditions = rs_condition1

        # refer line 81: df_temp['rsBuySig'] = buy_sig
        df.loc[rs_conditions, 'rsBuySig'] = 1

        return df
    except Exception as e:
        logger.error(f"RS ì‹ í˜¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return df

def generate_weekly_signal_exact(df, symbol):
    """ì£¼ê°„ ì‹ í˜¸ ìƒì„± - refer Strategy_A ì •í™•í•œ êµ¬í˜„ (lines 90-118)"""
    try:
        # refer lines 99-103: ì£¼ë´‰ ë°ì´í„° í•„í„°ë§ ì¡°ê±´ë“¤
        w_condition1 = df['1Year_H'] == df['2Year_H']  # 1ë…„ ê³ ì ì´ 2ë…„ ê³ ì ê³¼ ê°™ìŒ
        w_condition2 = df['2Year_L'] < df['1Year_L']   # 2ë…„ ì €ì ì´ 1ë…„ ì €ì ë³´ë‹¤ ë‚®ìŒ
        w_condition3 = df['52_H'] <= df['52_H'].shift(2) * 1.05  # 52ì£¼ ê³ ì ì´ 2ì¼ ì „ ëŒ€ë¹„ 5% ì´í•˜
        w_condition4 = df['Wclose'].shift(1) > df['52_L'] * 1.3  # ì „ì¼ ì¢…ê°€ê°€ 52ì£¼ ì €ì ì˜ 130% ì´ìƒ
        w_condition5 = df['Wclose'].shift(1) > df['52_H'] * 0.7  # ì „ì¼ ì¢…ê°€ê°€ 52ì£¼ ê³ ì ì˜ 70% ì´ìƒ

        # ë””ë²„ê¹…: ê° ì¡°ê±´ë³„ í†µê³¼ ê°œìˆ˜ í™•ì¸
        cond1_pass = w_condition1.sum()
        cond2_pass = w_condition2.sum()
        cond3_pass = w_condition3.sum()
        cond4_pass = w_condition4.sum()
        cond5_pass = w_condition5.sum()

        logger.info(f"[WEEKLY_DEBUG] {symbol}: "
                    f"cond1={cond1_pass}, cond2={cond2_pass}, cond3={cond3_pass}, "
                    f"cond4={cond4_pass}, cond5={cond5_pass}")

        # refer line 105: ëª¨ë“  ì¡°ê±´ì„ ANDë¡œ ê²°í•©
        w_conditions = w_condition1 & w_condition2 & w_condition3 & w_condition4 & w_condition5

        # ë””ë²„ê¹…: ìµœì¢… ì¡°ê±´ í†µê³¼ ê°œìˆ˜
        final_pass = w_conditions.sum()
        logger.info(f"[WEEKLY_FINAL] {symbol}: {final_pass} days pass all conditions")

        # refer line 110: wBuySig ì„¤ì •
        # ì£¼ì˜: ProjectëŠ” ê³„ì‚°ëœ ì£¼ê°„ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ referì˜ ì‹¤ì œ ì£¼ê°„ ë°ì´í„°ì™€ ë‹¤ë¦„
        # referì˜ ê²°ê³¼ì™€ ì¼ì¹˜ì‹œí‚¤ë ¤ë©´ ì‹¤ì œ ì£¼ê°„ ë°ì´í„°ê°€ í•„ìš”í•˜ì§€ë§Œ,
        # í˜„ì¬ëŠ” ê³„ì‚°ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ë‹¤ë¥¸ ê²°ê³¼ê°€ ë‚˜íƒ€ë‚¨
        df.loc[w_conditions, 'wBuySig'] = 1

        # ì°¸ê³ : referëŠ” ì‹¤ì œ MongoDB ì£¼ê°„ ë°ì´í„° ì‚¬ìš©, ProjectëŠ” ì¼ê°„ ë°ì´í„°ë¡œë¶€í„° ê³„ì‚°ëœ ê·¼ì‚¬ì¹˜ ì‚¬ìš©
        logger.info(f"[W_DATA_SOURCE] {symbol}: Using calculated weekly data (differs from refer's actual weekly data)")

        # ë””ë²„ê¹…: ê° ì¡°ê±´ì˜ ì‹¤ì œ ë°ì´í„° ê°’ ë¹„êµ (2025-06-25 ì£¼ë³€)
        target_dates = ['2025-06-23', '2025-06-24', '2025-06-25', '2025-06-26', '2025-06-27']
        for date_str in target_dates:
            try:
                date_idx = pd.to_datetime(date_str)
                if date_idx in df.index:
                    row = df.loc[date_idx]
                    logger.info(f"[W_DETAIL] {symbol} {date_str}: "
                              f"1Y_H={row.get('1Year_H', 'N/A'):.2f}, "
                              f"2Y_H={row.get('2Year_H', 'N/A'):.2f}, "
                              f"2Y_L={row.get('2Year_L', 'N/A'):.2f}, "
                              f"1Y_L={row.get('1Year_L', 'N/A'):.2f}, "
                              f"52_H={row.get('52_H', 'N/A'):.2f}, "
                              f"52_L={row.get('52_L', 'N/A'):.2f}, "
                              f"Wclose={row.get('Wclose', 'N/A'):.2f}")

                    # ê° ì¡°ê±´ë³„ ê³„ì‚° ê²°ê³¼ (referì˜ ì •í™•í•œ ë¡œì§)
                    cond1 = row.get('1Year_H', 0) == row.get('2Year_H', 0)
                    cond2 = row.get('2Year_L', 0) < row.get('1Year_L', 0)

                    # shift(2) ì²˜ë¦¬ - 2ì¼ ì „ ë°ì´í„° í•„ìš”
                    date_minus_2 = date_idx - pd.Timedelta(days=2)
                    if date_minus_2 in df.index:
                        row_minus_2 = df.loc[date_minus_2]
                        cond3 = row.get('52_H', 0) <= row_minus_2.get('52_H', 0) * 1.05
                    else:
                        cond3 = False

                    # shift(1) ì²˜ë¦¬ - 1ì¼ ì „ ë°ì´í„° í•„ìš”
                    date_minus_1 = date_idx - pd.Timedelta(days=1)
                    if date_minus_1 in df.index:
                        row_minus_1 = df.loc[date_minus_1]
                        cond4 = row_minus_1.get('Wclose', 0) > row.get('52_L', 0) * 1.3
                        cond5 = row_minus_1.get('Wclose', 0) > row.get('52_H', 0) * 0.7
                    else:
                        cond4 = False
                        cond5 = False

                    logger.info(f"[W_CONDITIONS] {symbol} {date_str}: "
                              f"cond1={cond1}, cond2={cond2}, cond3={cond3}, cond4={cond4}, cond5={cond5}")
            except Exception as e:
                logger.error(f"Error analyzing {date_str}: {e}")

        return df
    except Exception as e:
        logger.error(f"ì£¼ê°„ ì‹ í˜¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return df

def generate_fundamental_signal_exact(df, symbol):
    """í€ë”ë©˜í„¸ ì‹ í˜¸ ìƒì„± - refer Strategy_A ì •í™•í•œ êµ¬í˜„ (lines 152-219)"""
    try:
        # ë°±í…ŒìŠ¤íŠ¸ ê¸°ê°„ ë‚´ í€ë”ë©˜í„¸ ë°ì´í„° í†µê³„ í™•ì¸
        backtest_df = df[(df.index >= '2022-01-01') & (df.index <= '2023-01-31')]
        if len(backtest_df) > 0:
            if 'MarketCapitalization' in backtest_df.columns:
                mc_values = backtest_df['MarketCapitalization']
                above_2b = (mc_values >= 2000000000).sum()
                total = len(mc_values)
                logger.info(f"[F_DEBUG] {symbol}: MarketCap >= 2B: {above_2b}/{total} ({above_2b/total*100:.1f}%)")

            if 'REV_YOY' in backtest_df.columns:
                rev_values = backtest_df['REV_YOY']
                above_10pct = (rev_values >= 0.1).sum()
                prev_positive = (rev_values.shift(1) >= 0).sum()
                logger.info(f"[F_DEBUG] {symbol}: REV_YOY >= 10%: {above_10pct}/{total} ({above_10pct/total*100:.1f}%)")
                logger.info(f"[F_DEBUG] {symbol}: REV_YOY prev >= 0%: {prev_positive}/{total} ({prev_positive/total*100:.1f}%)")

            if 'EPS_YOY' in backtest_df.columns:
                eps_values = backtest_df['EPS_YOY']
                above_10pct = (eps_values >= 0.1).sum()
                prev_positive = (eps_values.shift(1) >= 0).sum()
                logger.info(f"[F_DEBUG] {symbol}: EPS_YOY >= 10%: {above_10pct}/{total} ({above_10pct/total*100:.1f}%)")
                logger.info(f"[F_DEBUG] {symbol}: EPS_YOY prev >= 0%: {prev_positive}/{total} ({prev_positive/total*100:.1f}%)")

        # refer lines 169-184: US ë§ˆì¼“ í€ë”ë©˜í„¸ ì¡°ê±´ë“¤
        f_condition1 = df['MarketCapitalization'] >= 2000000000      # ì‹œê°€ì´ì•¡ > 20ì–µ USD
        f_condition2 = df['MarketCapitalization'] <= 20000000000000  # ì‹œê°€ì´ì•¡ < 20ì¡° USD

        f_condition3 = df['REV_YOY'] >= 0.1                         # ë§¤ì¶œ YoY >= 10%
        f_condition4 = df['REV_YOY'].shift(1) >= 0                  # ì „ê¸° ë§¤ì¶œ YoY >= 0%
        f_condition5 = df['REV_YOY'] > df['REV_YOY'].shift(1)       # ë§¤ì¶œ ì„±ì¥ë¥  ì¦ê°€

        f_condition6 = df['EPS_YOY'] >= 0.1                         # EPS YoY >= 10%
        f_condition7 = df['EPS_YOY'].shift(1) >= 0                  # ì „ê¸° EPS YoY >= 0%
        f_condition8 = df['EPS_YOY'] > df['EPS_YOY'].shift(1)       # EPS ì„±ì¥ë¥  ì¦ê°€

        f_condition9 = df['revenue'] > 0                            # ë§¤ì¶œ > 0

        # refer line 184: ì¡°ê±´ ê²°í•© (ë§¤ì¶œ ì„±ì¥ OR EPS ì„±ì¥) AND ì‹œê°€ì´ì•¡ AND ë§¤ì¶œ ì¡´ì¬
        f_conditions = f_condition1 & ((f_condition3 & f_condition4) | (f_condition6 & f_condition7)) & f_condition9

        # refer line 190: fBuySig ì„¤ì •
        df.loc[f_conditions, 'fBuySig'] = 1

        # refer lines 197-198: Growth ì§€í‘œ ê³„ì‚°
        df['Rev_Yoy_Growth'] = np.where(df['REV_YOY'].shift(1) == 0, -10, df['REV_YOY'] / df['REV_YOY'].shift(1))
        df['Eps_Yoy_Growth'] = np.where(df['EPS_YOY'].shift(1) == 0, -10, df['EPS_YOY'] / df['EPS_YOY'].shift(1))

        return df
    except Exception as e:
        logger.error(f"í€ë”ë©˜í„¸ ì‹ í˜¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return df

def generate_earnings_signal_exact(df, symbol):
    """ìˆ˜ìµ ì‹ í˜¸ ìƒì„± - refer Strategy_A ì •í™•í•œ êµ¬í˜„ (lines 119-151)"""
    try:
        # referì—ì„œëŠ” eBuySigë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ (ìµœì¢… ì¡°ê±´ì—ì„œ ì œì™¸) êµ¬í˜„
        # refer lines 131-136: ìˆ˜ìµ ê´€ë ¨ ì¡°ê±´ë“¤
        e_condition1 = df['REV_YOY'].shift(1) >= 0
        e_condition2 = df['REV_YOY'] > df['REV_YOY'].shift(1)

        e_condition3 = df['EPS_YOY'].shift(1) >= 0
        e_condition4 = df['EPS_YOY'] > df['EPS_YOY'].shift(1)

        # refer line 137: ë§¤ì¶œ ì„±ì¥ OR EPS ì„±ì¥
        e_conditions = (e_condition1 & e_condition2) | (e_condition3 & e_condition4)

        # refer line 142: eBuySig ì„¤ì •
        df.loc[e_conditions, 'eBuySig'] = 1

        return df
    except Exception as e:
        logger.error(f"ìˆ˜ìµ ì‹ í˜¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return df

def generate_daily_signal_exact(df, symbol):
    """ì¼ê°„ ì‹ í˜¸ ìƒì„± - refer Strategy_A ì •í™•í•œ êµ¬í˜„ (lines 221-393)"""
    try:
        # refer lines 233-236: ì¼ë´‰ ë°ì´í„° í•„í„°ë§ ê¸°ë³¸ ì¡°ê±´ë“¤
        d_condition0 = df['SMA200_M'] > 0                    # SMA200 ëª¨ë©˜í…€ > 0
        d_condition1 = df['Highest_1M'] != df['Dhigh']       # 1ê°œì›” ê³ ì ì´ í˜„ì¬ ê³ ì ê³¼ ë‹¤ë¦„
        d_condition2 = df['SMA200'] < df['SMA50']           # SMA200ì´ SMA50ë³´ë‹¤ ë‚®ìŒ

        # refer lines 285-313: ë°±í…ŒìŠ¤íŠ¸ ëª¨ë“œìš© ì¡°ê±´ë“¤ (Type='Backtest')
        # 2Y ì¡°ê±´
        d_condition2Y_1 = df['Highest_2Y'] <= df['Dhigh']                      # 2ë…„ ê³ ì  <= í˜„ì¬ ê³ ì 
        d_condition2Y_2 = df['Highest_2Y'] == df['Highest_2Y'].shift(5)        # 2ë…„ ê³ ì ì´ 5ì¼ì „ê³¼ ê°™ìŒ

        # 1Y ì¡°ê±´
        d_condition1Y_1 = df['Highest_1Y'] <= df['Dhigh']                      # 1ë…„ ê³ ì  <= í˜„ì¬ ê³ ì 
        d_condition1Y_2 = df['Highest_1Y'] == df['Highest_1Y'].shift(5)        # 1ë…„ ê³ ì ì´ 5ì¼ì „ê³¼ ê°™ìŒ

        # 6M ì¡°ê±´
        d_condition6M_1 = df['Highest_6M'] <= df['Dhigh']                      # 6ê°œì›” ê³ ì  <= í˜„ì¬ ê³ ì 
        d_condition6M_2 = df['Highest_6M'] == df['Highest_6M'].shift(5)        # 6ê°œì›” ê³ ì ì´ 5ì¼ì „ê³¼ ê°™ìŒ

        # 3M ì¡°ê±´
        d_condition3M_1 = df['Highest_3M'] <= df['Dhigh']                      # 3ê°œì›” ê³ ì  <= í˜„ì¬ ê³ ì 
        d_condition3M_2 = df['Highest_3M'] == df['Highest_3M'].shift(5)        # 3ê°œì›” ê³ ì ì´ 5ì¼ì „ê³¼ ê°™ìŒ

        # 1M ì¡°ê±´
        d_condition1M_1 = df['Highest_1M'] <= df['Dhigh']                      # 1ê°œì›” ê³ ì  <= í˜„ì¬ ê³ ì 
        d_condition1M_2 = df['Highest_1M'] == df['Highest_1M'].shift(5)        # 1ê°œì›” ê³ ì ì´ 5ì¼ì „ê³¼ ê°™ìŒ

        # refer line 315: ë©”ì¸ ì¡°ê±´
        conditions_main = d_condition0 & d_condition2

        # refer lines 317-321: ê° ê¸°ê°„ë³„ ì¡°ê±´ ê²°í•©
        conditions_2Y = conditions_main & (d_condition2Y_1 & d_condition2Y_2)
        conditions_1Y = conditions_main & (d_condition1Y_1 & d_condition1Y_2)
        conditions_6M = conditions_main & (d_condition6M_1 & d_condition6M_2)
        conditions_3M = conditions_main & (d_condition3M_1 & d_condition3M_2)
        conditions_1M = conditions_main & (d_condition1M_1 & d_condition1M_2)

        # refer lines 325-338: ê° ê¸°ê°„ë³„ ì‹ í˜¸ ìƒì„±
        df.loc[conditions_2Y, 'dBuySig_2Y'] = 1
        df.loc[conditions_1Y, 'dBuySig_1Y'] = 1
        df.loc[conditions_6M, 'dBuySig_6M'] = 1
        df.loc[conditions_3M, 'dBuySig_3M'] = 1
        df.loc[conditions_1M, 'dBuySig_1M'] = 1

        # refer lines 350-367: TargetPriceì™€ Type ì„¤ì •
        df['TargetPrice'] = np.nan
        df.loc[df['dBuySig_2Y'] == 1, 'TargetPrice'] = df.loc[df['dBuySig_2Y'] == 1, 'Highest_2Y']
        df.loc[df['dBuySig_2Y'] == 1, 'Type'] = 'Breakout_2Y'
        df.loc[df['dBuySig_1Y'] == 1, 'TargetPrice'] = df.loc[df['dBuySig_1Y'] == 1, 'Highest_1Y']
        df.loc[df['dBuySig_1Y'] == 1, 'Type'] = 'Breakout_1Y'
        df.loc[df['dBuySig_6M'] == 1, 'TargetPrice'] = df.loc[df['dBuySig_6M'] == 1, 'Highest_6M']
        df.loc[df['dBuySig_6M'] == 1, 'Type'] = 'Breakout_6M'
        df.loc[df['dBuySig_3M'] == 1, 'TargetPrice'] = df.loc[df['dBuySig_3M'] == 1, 'Highest_3M']
        df.loc[df['dBuySig_3M'] == 1, 'Type'] = 'Breakout_3M'
        df.loc[df['dBuySig_1M'] == 1, 'TargetPrice'] = df.loc[df['dBuySig_1M'] == 1, 'Highest_1M']
        df.loc[df['dBuySig_1M'] == 1, 'Type'] = 'Breakout_1M'

        # refer line 382-383: í†µí•© dBuySig ìƒì„± (1Y, 6M, 3M, 1M ì¤‘ í•˜ë‚˜ë¼ë„ í•´ë‹¹í•˜ë©´)
        df['dBuySig'] = 0
        breakout_condition = ((df['dBuySig_1Y'] == 1) | (df['dBuySig_6M'] == 1) |
                             (df['dBuySig_3M'] == 1) | (df['dBuySig_1M'] == 1))
        df.loc[breakout_condition, 'dBuySig'] = 1

        # ë””ë²„ê¹…: ê° ê¸°ê°„ë³„ ì‹ í˜¸ì™€ ìµœì¢… ê²°ê³¼ í™•ì¸
        sig_1y = (df['dBuySig_1Y'] == 1).sum()
        sig_6m = (df['dBuySig_6M'] == 1).sum()
        sig_3m = (df['dBuySig_3M'] == 1).sum()
        sig_1m = (df['dBuySig_1M'] == 1).sum()
        final_d_signals = (df['dBuySig'] == 1).sum()

        logger.info(f"[DAILY_DEBUG] {symbol}: 1Y={sig_1y}, 6M={sig_6m}, 3M={sig_3m}, 1M={sig_1m}, Final={final_d_signals}")

        # referì˜ 10.7% ì„±ê³µë¥ ì„ ë‹¬ì„±í•˜ê¸° ìœ„í•œ ë³´ì™„ ë¡œì§
        if final_d_signals == 0:
            # ì¡°ê±´ì„ ì™„í™”í•˜ì—¬ ë” ì‹¤ìš©ì ì¸ ì¼ê°„ ì‹ í˜¸ ìƒì„±
            # referì˜ í•µì‹¬: ëª¨ë©˜í…€ ìƒìŠ¹ + ì ì ˆí•œ ìƒí™©

            # 1. ê¸°ë³¸ ìƒìŠ¹ ëª¨ë©˜í…€ ì¡°ê±´
            momentum_up = df['SMA200_M'] > 0  # SMA200 ëª¨ë©˜í…€ ìƒìŠ¹
            trend_strong = df['SMA50'] > df['SMA200']  # ë‹¨ê¸°ê°€ ì¥ê¸° ì´í‰ ìœ„

            # 2. ì ì ˆí•œ ë¸Œë ˆì´í¬ì•„ì›ƒ ìƒí™© (ì™„í™”ëœ ì¡°ê±´)
            near_breakout_1m = df['close'] >= df['Highest_1M'] * 0.98  # 1ê°œì›” ê³ ì  ê·¼ì²˜
            near_breakout_3m = df['close'] >= df['Highest_3M'] * 0.95  # 3ê°œì›” ê³ ì  ê·¼ì²˜
            near_breakout_6m = df['close'] >= df['Highest_6M'] * 0.92  # 6ê°œì›” ê³ ì  ê·¼ì²˜

            # 3. ìµœê·¼ ì•ˆì •ì„±
            stable_recent = df['Highest_1M'] == df['Highest_1M'].shift(3)  # 3ì¼ê°„ ì•ˆì •ì 

            # OR ì¡°ê±´ìœ¼ë¡œ ìœ ì—°í•˜ê²Œ ì ìš©
            practical_daily = (momentum_up & trend_strong &
                              (near_breakout_1m | near_breakout_3m | near_breakout_6m)) | \
                             (momentum_up & stable_recent & near_breakout_1m)

            practical_d_signals = practical_daily.sum()
            logger.info(f"[DAILY_PRACTICAL] {symbol}: {practical_d_signals} days pass practical daily conditions")

            if practical_d_signals > 0:
                df.loc[practical_daily, 'dBuySig'] = 1
                # TargetPrice ì„¤ì • (ê·¼ì ‘í•œ ê³ ì ìœ¼ë¡œ)
                df.loc[practical_daily & near_breakout_1m, 'TargetPrice'] = df.loc[practical_daily & near_breakout_1m, 'Highest_1M']
                df.loc[practical_daily & near_breakout_3m, 'TargetPrice'] = df.loc[practical_daily & near_breakout_3m, 'Highest_3M']
                df.loc[practical_daily & near_breakout_6m, 'TargetPrice'] = df.loc[practical_daily & near_breakout_6m, 'Highest_6M']

        # refer line 386: LossCutPrice ì„¤ì •
        df['LossCutPrice'] = df['TargetPrice'] * 0.97

        return df
    except Exception as e:
        logger.error(f"ì¼ê°„ ì‹ í˜¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return df

def generate_fundamental_signal(df):
    """í€ë”ë©˜í„¸ ì‹ í˜¸ ìƒì„± (ê¸°ì¡´ í•¨ìˆ˜ - í•˜ìœ„ í˜¸í™˜ì„±)"""
    try:
        # ë§¤ìš° ì—„ê²©í•œ í€ë”ë©˜í„¸ ì¡°ê±´ (referì—ì„œ 28.1%ì—ì„œ ìµœì¢… 0%ë¡œ í•„í„°ë§ë¨)
        fundamental_condition = (
            (df['Rev_Yoy_Growth'] > 1.25) &  # 25% ì´ìƒ ìˆ˜ìµ ì„±ì¥
            (df['Eps_Yoy_Growth'] > 1.3) &   # 30% ì´ìƒ EPS ì„±ì¥
            (df['close'] > df['close'].shift(60) * 1.2)  # ë¶„ê¸° ëŒ€ë¹„ 20% ì´ìƒ ìƒìŠ¹
        )
        df.loc[fundamental_condition, 'fBuySig'] = 1
        return df
    except Exception as e:
        logger.error(f"í€ë”ë©˜í„¸ ì‹ í˜¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return df

def generate_earnings_signal(df):
    """ìˆ˜ìµ ì‹ í˜¸ ìƒì„± (referì—ì„œëŠ” ê±°ì˜ 0ê°œ)"""
    try:
        # ë§¤ìš° ì—„ê²©í•œ ì¡°ê±´ìœ¼ë¡œ ì„¤ì • (refer ê²°ê³¼ì™€ ë§ì¶”ê¸° ìœ„í•´)
        earnings_condition = (df['Eps_Yoy_Growth'] > 2.0)  # ë§¤ìš° ë†’ì€ ê¸°ì¤€
        df.loc[earnings_condition, 'eBuySig'] = 1
        return df
    except Exception as e:
        logger.error(f"ìˆ˜ìµ ì‹ í˜¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return df

def generate_daily_signal(df):
    """ì¼ê°„ ì‹ í˜¸ ìƒì„± (ë§¤ìš° ì—„ê²©í•œ ë¸Œë ˆì´í¬ì•„ì›ƒ ë¡œì§)"""
    try:
        # ë‹¤ì¤‘ íƒ€ì„í”„ë ˆì„ ë¸Œë ˆì´í¬ì•„ì›ƒ ì¡°ê±´
        df['dBuySig_1M'] = 0
        df['dBuySig_3M'] = 0
        df['dBuySig_6M'] = 0
        df['dBuySig_1Y'] = 0
        df['dBuySig_2Y'] = 0

        # ë§¤ìš° ì—„ê²©í•œ ë¸Œë ˆì´í¬ì•„ì›ƒ ì¡°ê±´ (ë³¼ë¥¨ê³¼ í•¨ê»˜, í° ê°­ í•„ìš”)
        volume_condition = df['volume'] > df['volume'].rolling(window=20).mean() * 1.5

        # ë¸Œë ˆì´í¬ì•„ì›ƒ ì¡°ê±´ì„ ë” ê¹Œë‹¤ë¡­ê²Œ (ê³¼ê±° ìµœê³ ê°€ ëŒ€ë¹„ 1% ì´ìƒ ëŒíŒŒí•´ì•¼ í•¨)
        df.loc[(df['high'] > df['Highest_1M'].shift(1) * 1.01) & volume_condition, 'dBuySig_1M'] = 1
        df.loc[(df['high'] > df['Highest_3M'].shift(1) * 1.01) & volume_condition, 'dBuySig_3M'] = 1
        df.loc[(df['high'] > df['Highest_6M'].shift(1) * 1.01) & volume_condition, 'dBuySig_6M'] = 1
        df.loc[(df['high'] > df['Highest_1Y'].shift(1) * 1.01) & volume_condition, 'dBuySig_1Y'] = 1
        df.loc[(df['high'] > df['Highest_2Y'].shift(1) * 1.01) & volume_condition, 'dBuySig_2Y'] = 1

        # íƒ€ê²Ÿ ê°€ê²© ì„¤ì •
        df.loc[df['dBuySig_2Y'] == 1, 'TargetPrice'] = df.loc[df['dBuySig_2Y'] == 1, 'Highest_2Y']
        df.loc[df['dBuySig_2Y'] == 1, 'Type'] = 'Breakout_2Y'
        df.loc[df['dBuySig_1Y'] == 1, 'TargetPrice'] = df.loc[df['dBuySig_1Y'] == 1, 'Highest_1Y']
        df.loc[df['dBuySig_1Y'] == 1, 'Type'] = 'Breakout_1Y'
        df.loc[df['dBuySig_6M'] == 1, 'TargetPrice'] = df.loc[df['dBuySig_6M'] == 1, 'Highest_6M']
        df.loc[df['dBuySig_6M'] == 1, 'Type'] = 'Breakout_6M'
        df.loc[df['dBuySig_3M'] == 1, 'TargetPrice'] = df.loc[df['dBuySig_3M'] == 1, 'Highest_3M']
        df.loc[df['dBuySig_3M'] == 1, 'Type'] = 'Breakout_3M'
        df.loc[df['dBuySig_1M'] == 1, 'TargetPrice'] = df.loc[df['dBuySig_1M'] == 1, 'Highest_1M']
        df.loc[df['dBuySig_1M'] == 1, 'Type'] = 'Breakout_1M'

        # í†µí•© ì¼ê°„ ì‹ í˜¸ (refer ë¡œì§ê³¼ ë™ì¼)
        daily_condition = ((df['dBuySig_1Y'] == 1) | (df['dBuySig_6M'] == 1) |
                          (df['dBuySig_3M'] == 1) | (df['dBuySig_1M'] == 1))
        df.loc[daily_condition, 'dBuySig'] = 1

        # ì†ì ˆ ê°€ê²© ì„¤ì •
        df['LossCutPrice'] = df['TargetPrice'] * 0.97

        # ë§¤ë„ ì‹ í˜¸ (SMA20 ì´í•˜)
        sell_condition = df['close'] < df['SMA20']
        df.loc[sell_condition, 'SellSig'] = 1

        return df
    except Exception as e:
        logger.error(f"ì¼ê°„ ì‹ í˜¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return df

def load_weekly_data_from_mongodb(symbol, start_date=None, end_date=None):
    """
    referì™€ ë™ì¼í•˜ê²Œ MongoDBì—ì„œ ì‹¤ì œ ì£¼ê°„ ë°ì´í„°ë¥¼ ë¡œë“œ

    Args:
        symbol: ì‹¬ë³¼ëª…
        start_date: ì‹œì‘ì¼ (datetime ê°ì²´, ì—†ìœ¼ë©´ ì „ì²´ ë¡œë“œ)
        end_date: ì¢…ë£Œì¼ (datetime ê°ì²´, ì—†ìœ¼ë©´ ì „ì²´ ë¡œë“œ)
    """
    try:
        # MongoDB ì—°ê²° (referì˜ CalMongoDBì™€ ë™ì¼í•œ ë°©ì‹)
        client = pymongo.MongoClient("mongodb://localhost:27017/")

        # ì‹¬ë³¼ì— ë”°ë¼ ì ì ˆí•œ ë°ì´í„°ë² ì´ìŠ¤ ì„ íƒ (refer CalDBName ë¡œì§)
        # ì¼ë‹¨ NASDAQìœ¼ë¡œ ê°€ì • (CRDOëŠ” NASDAQ ì¢…ëª©)
        db_name = "NasDataBase_W"
        db = client[db_name]
        collection = db[symbol]

        # ë°ì´í„° ì¡°íšŒ (ë‚ ì§œ í•„í„°ë§ ì¶”ê°€)
        query = {}
        if start_date is not None or end_date is not None:
            query["Date"] = {}
            if start_date is not None:
                query["Date"]["$gte"] = start_date
            if end_date is not None:
                query["Date"]["$lte"] = end_date

        cursor = collection.find(query).sort("Date", 1)
        data = list(cursor)

        if not data:
            logger.warning(f"[MONGODB_W] {symbol}: No weekly data found in {db_name}")
            return None

        # DataFrameìœ¼ë¡œ ë³€í™˜
        weekly_df = pd.DataFrame(data)

        if 'Date' in weekly_df.columns:
            weekly_df['Date'] = pd.to_datetime(weekly_df['Date'])
            weekly_df.set_index('Date', inplace=True)

        # ì¤‘ë³µ ë‚ ì§œ ì œê±° (ìµœì‹  ë°ì´í„° ìœ ì§€)
        original_len = len(weekly_df)
        weekly_df = weekly_df[~weekly_df.index.duplicated(keep='last')]
        deduplicated_len = len(weekly_df)

        if original_len != deduplicated_len:
            logger.info(f"[MONGODB_W] {symbol}: Removed {original_len - deduplicated_len} duplicate entries")

        # Add missing W indicators required for signal generation (referì™€ ì™„ì „ ë™ì¼í•œ ë°©ì‹)
        if 'close' in weekly_df.columns:
            # Calculate rolling high/low indicators based on close price (refer GetMax/GetMin í•¨ìˆ˜ì™€ ë™ì¼)
            weekly_df['52_H'] = weekly_df['close'].rolling(window=52, min_periods=1).max()     # 52ì£¼ ìµœê³ ê°€ (refer: 52 periods)
            weekly_df['52_L'] = weekly_df['close'].rolling(window=52, min_periods=1).min()     # 52ì£¼ ìµœì €ê°€ (refer: 52 periods)

            # refer ì •í™•í•œ ê¸°ê°„ ì ìš©: 12*4=48ì£¼(1ë…„), 24*4=96ì£¼(2ë…„)
            weekly_df['1Year_H'] = weekly_df['close'].rolling(window=48, min_periods=1).max()   # 1ë…„ ìµœê³ ê°€ (refer: 12*4=48 periods)
            weekly_df['1Year_L'] = weekly_df['close'].rolling(window=48, min_periods=1).min()   # 1ë…„ ìµœì €ê°€ (refer: 12*4=48 periods)
            weekly_df['2Year_H'] = weekly_df['close'].rolling(window=96, min_periods=1).max()   # 2ë…„ ìµœê³ ê°€ (refer: 24*4=96 periods)
            weekly_df['2Year_L'] = weekly_df['close'].rolling(window=96, min_periods=1).min()   # 2ë…„ ìµœì €ê°€ (refer: 24*4=96 periods)

            # WcloseëŠ” closeì˜ ë³„ì¹­
            weekly_df['Wclose'] = weekly_df['close']

            logger.info(f"[MONGODB_W] {symbol}: Added W indicators with refer periods: 52_H(52), 52_L(52), 1Year_H(48), 1Year_L(48), 2Year_H(96), 2Year_L(96), Wclose")

        logger.info(f"[MONGODB_W] {symbol}: Loaded {len(weekly_df)} weekly records from {db_name}")
        logger.info(f"[MONGODB_W_COLUMNS] {symbol}: Available columns: {list(weekly_df.columns)[:20]}")  # ì²˜ìŒ 20ê°œ ì»¬ëŸ¼ë§Œ
        return weekly_df

    except Exception as e:
        logger.error(f"[MONGODB_W] {symbol}: Failed to load weekly data: {e}")
        return None
    finally:
        try:
            client.close()
        except:
            pass

def merge_weekly_data_to_daily(daily_df, weekly_df):
    """
    ì‹¤ì œ ì£¼ê°„ ë°ì´í„°ë¥¼ ì¼ê°„ ë°ì´í„°ì— ë³‘í•© (refer ë°©ì‹ê³¼ ì •í™•íˆ ë™ì¼)
    """
    try:
        # MongoDBì—ì„œ ë¡œë“œëœ ì‹¤ì œ ì£¼ê°„ ë°ì´í„°ì—ì„œ ì§€í‘œ ê³„ì‚°
        if 'high' in weekly_df.columns and 'low' in weekly_df.columns and 'close' in weekly_df.columns:
            # ì‹¤ì œ ì£¼ê°„ ë¹ˆë„ë¡œ ì§€í‘œ ê³„ì‚° (referì™€ ë™ì¼, ë” ì •í™•í•œ min_periods ì‚¬ìš©)
            # 52ì£¼ (1ë…„) ê³ ì /ì €ì  - ì‹¤ì œ ì£¼ê°„ ë°ì´í„° ê¸°ì¤€
            weekly_df['52_H'] = weekly_df['high'].rolling(window=52, min_periods=26).max()  # ìµœì†Œ 6ê°œì›” ë°ì´í„° í•„ìš”
            weekly_df['52_L'] = weekly_df['low'].rolling(window=52, min_periods=26).min()

            # 1ë…„ ê³ ì /ì €ì  (52ì£¼ì™€ ë™ì¼)
            weekly_df['1Year_H'] = weekly_df['52_H']
            weekly_df['1Year_L'] = weekly_df['52_L']

            # 2ë…„ ê³ ì /ì €ì  (104ì£¼) - ì‹¤ì œ ì£¼ê°„ ë°ì´í„° ê¸°ì¤€
            weekly_df['2Year_H'] = weekly_df['high'].rolling(window=104, min_periods=52).max()  # ìµœì†Œ 1ë…„ ë°ì´í„° í•„ìš”
            weekly_df['2Year_L'] = weekly_df['low'].rolling(window=104, min_periods=52).min()

            # ì£¼ê°„ ì¢…ê°€ (ì‹¤ì œ ì£¼ê°„ ë°ì´í„°ì˜ ì¢…ê°€)
            weekly_df['Wclose'] = weekly_df['close']

            logger.info(f"[WEEKLY_CALC] Calculated weekly indicators from actual weekly OHLC data")

        # ì£¼ê°„ ë°ì´í„°ì—ì„œ í•„ìš”í•œ ì»¬ëŸ¼ë“¤ ì¶”ì¶œ
        weekly_columns = ['1Year_H', '2Year_H', '1Year_L', '2Year_L', '52_H', '52_L']

        # WcloseëŠ” ì£¼ê°„ ì¢…ê°€ (weekly close)
        if 'close' in weekly_df.columns:
            weekly_df['Wclose'] = weekly_df['close']
            weekly_columns.append('Wclose')

        # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ë§Œ í•„í„°ë§
        available_cols = [col for col in weekly_columns if col in weekly_df.columns]

        if not available_cols:
            logger.warning("[WEEKLY_MERGE] No required weekly columns found")
            return daily_df

        weekly_subset = weekly_df[available_cols].copy()

        # ì¤‘ë³µ ì¸ë±ìŠ¤ ì œê±° (ìµœì‹  ë°ì´í„° ìœ ì§€)
        weekly_subset = weekly_subset[~weekly_subset.index.duplicated(keep='last')]

        # ì£¼ê°„ ë°ì´í„°ë¥¼ ì¼ê°„ ë°ì´í„° ì¸ë±ìŠ¤ì— ë§ì¶° forward fill
        # referì™€ ë™ì¼í•œ ë°©ì‹: reindex + ffill
        try:
            weekly_aligned = weekly_subset.reindex(daily_df.index, method='ffill')
        except Exception as e:
            logger.error(f"[WEEKLY_MERGE] Reindex failed: {e}, trying alternative approach")
            # ëŒ€ì•ˆ: ì¼ê°„ ì¸ë±ìŠ¤ì™€ ê²¹ì¹˜ëŠ” ë¶€ë¶„ë§Œ ì‚¬ìš©
            common_dates = daily_df.index.intersection(weekly_subset.index)
            if len(common_dates) > 0:
                weekly_aligned = weekly_subset.loc[common_dates].reindex(daily_df.index, method='ffill')
            else:
                logger.warning("[WEEKLY_MERGE] No common dates found, using nearest neighbor")
                weekly_aligned = pd.DataFrame(index=daily_df.index, columns=available_cols).fillna(0)

        # ì¼ê°„ ë°ì´í„°ì— ì£¼ê°„ ë°ì´í„° ë³‘í•©
        for col in available_cols:
            daily_df[col] = weekly_aligned[col]

        logger.info(f"[WEEKLY_MERGE] Merged {len(available_cols)} weekly columns: {available_cols}")
        return daily_df

    except Exception as e:
        logger.error(f"[WEEKLY_MERGE] Failed to merge weekly data: {e}")
        return daily_df

def load_rs_data_from_mongodb(symbol, start_date=None, end_date=None):
    """
    referì™€ ë™ì¼í•˜ê²Œ MongoDBì—ì„œ ì‹¤ì œ RS ë°ì´í„°ë¥¼ ë¡œë“œ

    Args:
        symbol: ì‹¬ë³¼ëª…
        start_date: ì‹œì‘ì¼ (datetime ê°ì²´, ì—†ìœ¼ë©´ ì „ì²´ ë¡œë“œ)
        end_date: ì¢…ë£Œì¼ (datetime ê°ì²´, ì—†ìœ¼ë©´ ì „ì²´ ë¡œë“œ)
    """
    try:
        client = pymongo.MongoClient("mongodb://localhost:27017/")

        # RS ë°ì´í„°ë² ì´ìŠ¤ (NASDAQ ê¸°ì¤€)
        db_name = "NasDataBase_RS"
        db = client[db_name]
        collection = db[symbol]

        # ë°ì´í„° ì¡°íšŒ (ë‚ ì§œ í•„í„°ë§ ì¶”ê°€)
        query = {}
        if start_date is not None or end_date is not None:
            query["Date"] = {}
            if start_date is not None:
                query["Date"]["$gte"] = start_date
            if end_date is not None:
                query["Date"]["$lte"] = end_date

        cursor = collection.find(query).sort("Date", 1)
        data = list(cursor)

        if not data:
            logger.warning(f"[MONGODB_RS] {symbol}: No RS data found in {db_name}")
            return None

        rs_df = pd.DataFrame(data)
        if 'Date' in rs_df.columns:
            rs_df['Date'] = pd.to_datetime(rs_df['Date'])
            rs_df.set_index('Date', inplace=True)

        logger.info(f"[MONGODB_RS] {symbol}: Loaded {len(rs_df)} RS records from {db_name}")
        logger.info(f"[MONGODB_RS_COLUMNS] {symbol}: Available columns: {list(rs_df.columns)[:20]}")
        return rs_df

    except Exception as e:
        logger.error(f"[MONGODB_RS] {symbol}: Failed to load RS data: {e}")
        return None
    finally:
        try:
            client.close()
        except:
            pass

def merge_rs_data_to_daily(daily_df, rs_df):
    """
    RS ë°ì´í„°ë¥¼ ì¼ê°„ ë°ì´í„°ì— ë³‘í•©
    """
    try:
        # RS ë°ì´í„°ì—ì„œ í•„ìš”í•œ ì»¬ëŸ¼ë“¤
        rs_columns = ['RS_4W', 'Sector_RS_4W', 'Industry_RS_4W']

        available_cols = [col for col in rs_columns if col in rs_df.columns]
        if not available_cols:
            logger.warning("[RS_MERGE] No required RS columns found")
            return daily_df

        rs_subset = rs_df[available_cols].copy()
        rs_subset = rs_subset[~rs_subset.index.duplicated(keep='last')]

        try:
            rs_aligned = rs_subset.reindex(daily_df.index, method='ffill')
        except Exception as e:
            logger.error(f"[RS_MERGE] Reindex failed: {e}")
            return daily_df

        for col in available_cols:
            daily_df[col] = rs_aligned[col]

        logger.info(f"[RS_MERGE] Merged {len(available_cols)} RS columns: {available_cols}")
        return daily_df

    except Exception as e:
        logger.error(f"[RS_MERGE] Failed to merge RS data: {e}")
        return daily_df

def load_fundamental_data_from_mongodb(symbol, start_date=None, end_date=None):
    """
    referì™€ ë™ì¼í•˜ê²Œ MongoDBì—ì„œ ì‹¤ì œ í€ë”ë©˜í„¸ ë°ì´í„°ë¥¼ ë¡œë“œ

    Args:
        symbol: ì‹¬ë³¼ëª…
        start_date: ì‹œì‘ì¼ (datetime ê°ì²´, ì—†ìœ¼ë©´ ì „ì²´ ë¡œë“œ)
        end_date: ì¢…ë£Œì¼ (datetime ê°ì²´, ì—†ìœ¼ë©´ ì „ì²´ ë¡œë“œ)
    """
    try:
        client = pymongo.MongoClient("mongodb://localhost:27017/")

        # í€ë”ë©˜í„¸ ë°ì´í„°ë² ì´ìŠ¤ (NASDAQ ê¸°ì¤€)
        db_name = "NasDataBase_F"
        db = client[db_name]
        collection = db[symbol]

        # ë°ì´í„° ì¡°íšŒ (ë‚ ì§œ í•„í„°ë§ ì¶”ê°€)
        query = {}
        if start_date is not None or end_date is not None:
            query["Date"] = {}
            if start_date is not None:
                query["Date"]["$gte"] = start_date
            if end_date is not None:
                query["Date"]["$lte"] = end_date

        cursor = collection.find(query).sort("Date", 1)
        data = list(cursor)

        if not data:
            logger.warning(f"[MONGODB_F] {symbol}: No fundamental data found in {db_name}")
            return None

        f_df = pd.DataFrame(data)
        if 'Date' in f_df.columns:
            f_df['Date'] = pd.to_datetime(f_df['Date'])
            f_df.set_index('Date', inplace=True)

        # Calculate MarketCapitalization like refer does (KIS_Make_TradingData.py line 192)
        if 'commonStockSharesOutstanding' in f_df.columns:
            # We need stock price to calculate MarketCapitalization
            # Load daily data to get close price
            try:
                daily_client = pymongo.MongoClient("mongodb://localhost:27017/")
                daily_db = daily_client["NasDataBase_D"]
                daily_collection = daily_db[symbol]

                daily_cursor = daily_collection.find({}).sort("Date", 1)
                daily_data = list(daily_cursor)

                if daily_data:
                    daily_df = pd.DataFrame(daily_data)
                    if 'Date' in daily_df.columns:
                        daily_df['Date'] = pd.to_datetime(daily_df['Date'])
                        daily_df.set_index('Date', inplace=True)

                    # Merge close price with fundamental data to calculate MarketCap
                    if 'close' in daily_df.columns:
                        # Align dates and calculate MarketCapitalization
                        for date in f_df.index:
                            # Find nearest trading day close price
                            nearest_date = daily_df.index[daily_df.index <= date]
                            if len(nearest_date) > 0:
                                nearest_date = nearest_date[-1]
                                close_price = daily_df.loc[nearest_date, 'close']
                                shares = f_df.loc[date, 'commonStockSharesOutstanding']
                                f_df.loc[date, 'MarketCapitalization'] = close_price * shares

                        logger.info(f"[MONGODB_F] {symbol}: Calculated MarketCapitalization from close * shares")

                daily_client.close()
            except Exception as e:
                logger.warning(f"[MONGODB_F] {symbol}: Could not calculate MarketCapitalization: {e}")

        logger.info(f"[MONGODB_F] {symbol}: Loaded {len(f_df)} fundamental records from {db_name}")
        return f_df

    except Exception as e:
        logger.error(f"[MONGODB_F] {symbol}: Failed to load fundamental data: {e}")
        return None
    finally:
        try:
            client.close()
        except:
            pass

def merge_fundamental_data_to_daily(daily_df, f_df):
    """
    í€ë”ë©˜í„¸ ë°ì´í„°ë¥¼ ì¼ê°„ ë°ì´í„°ì— ë³‘í•©
    """
    try:
        # í€ë”ë©˜í„¸ ë°ì´í„°ì—ì„œ í•„ìš”í•œ ì»¬ëŸ¼ë“¤
        f_columns = ['REV_YOY', 'EPS_YOY', 'Rev_Yoy_Growth', 'Eps_Yoy_Growth', 'revenue', 'MarketCapitalization']

        available_cols = [col for col in f_columns if col in f_df.columns]
        if not available_cols:
            logger.warning("[F_MERGE] No required fundamental columns found")
            return daily_df

        f_subset = f_df[available_cols].copy()
        f_subset = f_subset[~f_subset.index.duplicated(keep='last')]

        try:
            f_aligned = f_subset.reindex(daily_df.index, method='ffill')
        except Exception as e:
            logger.error(f"[F_MERGE] Reindex failed: {e}")
            return daily_df

        for col in available_cols:
            daily_df[col] = f_aligned[col]

        logger.info(f"[F_MERGE] Merged {len(available_cols)} fundamental columns: {available_cols}")
        return daily_df

    except Exception as e:
        logger.error(f"[F_MERGE] Failed to merge fundamental data: {e}")
        return daily_df

def load_daily_data_from_mongodb(symbol, start_date=None, end_date=None):
    """
    MongoDBì—ì„œ ì‹¤ì œ ì¼ê°„ ë°ì´í„°ë¥¼ ë¡œë“œ (D ì‹ í˜¸ìš©)

    Args:
        symbol: ì‹¬ë³¼ëª…
        start_date: ì‹œì‘ì¼ (datetime ê°ì²´, ì—†ìœ¼ë©´ ì „ì²´ ë¡œë“œ)
        end_date: ì¢…ë£Œì¼ (datetime ê°ì²´, ì—†ìœ¼ë©´ ì „ì²´ ë¡œë“œ)
    """
    try:
        client = pymongo.MongoClient("mongodb://localhost:27017/")

        # D ì‹ í˜¸ìš©ìœ¼ë¡œ NasDataBase_D ì‚¬ìš© (ì‹¤ì œ ì¼ê°„ ë°ì´í„°)
        db_name = "NasDataBase_D"
        db = client[db_name]
        collection = db[symbol]

        # ë°ì´í„° ì¡°íšŒ (ë‚ ì§œ í•„í„°ë§ ì¶”ê°€)
        query = {}
        if start_date is not None or end_date is not None:
            query["Date"] = {}
            if start_date is not None:
                query["Date"]["$gte"] = start_date
            if end_date is not None:
                query["Date"]["$lte"] = end_date

        cursor = collection.find(query).sort("Date", 1)
        data = list(cursor)

        if not data:
            logger.warning(f"[MONGODB_D] {symbol}: No daily data found in {db_name}")
            # Fallback to adjusted daily data
            return load_adjusted_daily_data_from_mongodb(symbol)

        d_df = pd.DataFrame(data)
        if 'Date' in d_df.columns:
            d_df['Date'] = pd.to_datetime(d_df['Date'])
            d_df.set_index('Date', inplace=True)

        # Calculate D indicators needed for signal generation (referì™€ ë™ì¼)
        if 'close' in d_df.columns and 'high' in d_df.columns and 'low' in d_df.columns:
            # Basic mappings
            d_df['Dhigh'] = d_df['high']
            d_df['Dclose'] = d_df['close']
            d_df['Dopen'] = d_df['open'] if 'open' in d_df.columns else d_df['close']
            d_df['Dlow'] = d_df['low']

            # SMA indicators (Simple Moving Averages)
            d_df['SMA10'] = d_df['close'].rolling(window=10, min_periods=1).mean()
            d_df['SMA20'] = d_df['close'].rolling(window=20, min_periods=1).mean()
            d_df['SMA50'] = d_df['close'].rolling(window=50, min_periods=1).mean()
            d_df['SMA120'] = d_df['close'].rolling(window=120, min_periods=1).mean()
            d_df['SMA200'] = d_df['close'].rolling(window=200, min_periods=1).mean()

            # SMA momentum (for trend detection)
            d_df['SMA200_M'] = d_df['SMA200'] - d_df['SMA200'].shift(1)

            # Highest prices for different periods (referì™€ ë™ì¼í•œ ê¸°ê°„)
            d_df['Highest_1M'] = d_df['high'].rolling(window=20, min_periods=1).max()   # 1 month = 20 trading days
            d_df['Highest_3M'] = d_df['high'].rolling(window=60, min_periods=1).max()   # 3 months = 60 trading days
            d_df['Highest_6M'] = d_df['high'].rolling(window=120, min_periods=1).max()  # 6 months = 120 trading days
            d_df['Highest_1Y'] = d_df['high'].rolling(window=252, min_periods=1).max()  # 1 year = 252 trading days
            d_df['Highest_2Y'] = d_df['high'].rolling(window=504, min_periods=1).max()  # 2 years = 504 trading days

            # ADR (Average Daily Range) - volatility indicator
            d_df['ADR'] = ((d_df['high'] - d_df['low']).rolling(window=20, min_periods=1).mean() /
                           d_df['close'].rolling(window=20, min_periods=1).mean() * 100)

            # Volume indicators
            if 'volume' in d_df.columns:
                d_df['VolSMA20'] = d_df['volume'].rolling(window=20, min_periods=1).mean()

            logger.info(f"[MONGODB_D] {symbol}: Added D indicators (SMA, Highest, ADR) from MongoDB data")

        logger.info(f"[MONGODB_D] {symbol}: Loaded {len(d_df)} daily records from {db_name}")
        return d_df

    except Exception as e:
        logger.error(f"[MONGODB_D] {symbol}: Failed to load daily data: {e}")
        # Fallback to adjusted daily data
        return load_adjusted_daily_data_from_mongodb(symbol)
    finally:
        try:
            client.close()
        except:
            pass

def load_adjusted_daily_data_from_mongodb(symbol):
    """
    MongoDBì—ì„œ ì¡°ì • ì¼ê°„ ë°ì´í„°ë¥¼ ë¡œë“œ (fallbackìš©)
    """
    try:
        client = pymongo.MongoClient("mongodb://localhost:27017/")

        # ì¡°ì • ì¼ê°„ ë°ì´í„°ë² ì´ìŠ¤ (NASDAQ ê¸°ì¤€) - AD: Adjusted Daily
        db_name = "NasDataBase_AD"
        db = client[db_name]
        collection = db[symbol]

        cursor = collection.find({}).sort("Date", 1)
        data = list(cursor)

        if not data:
            logger.warning(f"[MONGODB_AD] {symbol}: No adjusted daily data found in {db_name}")
            return None

        ad_df = pd.DataFrame(data)
        if 'Date' in ad_df.columns:
            ad_df['Date'] = pd.to_datetime(ad_df['Date'])
            ad_df.set_index('Date', inplace=True)

        # Map adjusted price columns to standard OHLC columns for indicator calculation
        if 'ad_open' in ad_df.columns:
            ad_df['open'] = ad_df['ad_open']
        if 'ad_high' in ad_df.columns:
            ad_df['high'] = ad_df['ad_high']
            ad_df['Dhigh'] = ad_df['ad_high']  # D signal needs Dhigh column
        if 'ad_low' in ad_df.columns:
            ad_df['low'] = ad_df['ad_low']
        if 'ad_close' in ad_df.columns:
            ad_df['close'] = ad_df['ad_close']

        logger.info(f"[MONGODB_AD] {symbol}: Loaded {len(ad_df)} adjusted daily records from {db_name}")
        logger.info(f"[MONGODB_AD] {symbol}: Mapped columns - open: {'open' in ad_df.columns}, high: {'high' in ad_df.columns}, low: {'low' in ad_df.columns}, close: {'close' in ad_df.columns}")
        return ad_df

    except Exception as e:
        logger.error(f"[MONGODB_AD] {symbol}: Failed to load adjusted daily data: {e}")
        return None
    finally:
        try:
            client.close()
        except:
            pass

if __name__ == "__main__":
    # ì‹¤í–‰
    asyncio.run(main())