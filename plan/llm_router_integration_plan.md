# LLM λΌμ°ν„° ν†µν•© κ³„ν

**ν”„λ΅μ νΈ**: AI Assistant Multi-Agent Trading System
**μ‘μ„±μΌ**: 2025-09-15
**λ‹΄λ‹Ή**: Orchestrator Agent
**λΌμ°ν„°**: https://github.com/musistudio/claude-code-router

---

## π― ν†µν•© λ©ν‘

### μ£Όμ” λ©ν‘
1. **Gemini λ¨λΈμ„ Claude Codeμ—μ„ μ‚¬μ© κ°€λ¥ν•κ² ν•¨**
2. **μ—μ΄μ „νΈλ³„ μµμ  λ¨λΈ μλ™ μ„ νƒ**
3. **λΉ„μ© ν¨μ¨μ μΈ LLM μ‚¬μ©**
4. **λ΅λ“ λ°Έλ°μ‹± λ° failover κµ¬ν„**

### μμƒ ν¨κ³Ό
- **λΉ„μ© μ κ°**: Gemini λ¨λΈ ν™μ©μΌλ΅ 30-50% λΉ„μ© μ μ•½
- **μ„±λ¥ ν–¥μƒ**: μ‘μ—…λ³„ μµμ  λ¨λΈ μ„ νƒμΌλ΅ μ‘λ‹µ ν’μ§ κ°μ„ 
- **μ•μ •μ„± ν™•λ³΄**: λ‹¤μ¤‘ λ¨λΈ μ§€μ›μΌλ΅ μ„λΉ„μ¤ μ—°μ†μ„± λ³΄μ¥

---

## π—οΈ μ•„ν‚¤ν…μ² μ„¤κ³„

### ν„μ¬ κµ¬μ΅°
```
Claude Code β†’ Anthropic API β†’ Claude Models Only
```

### λ©ν‘ κµ¬μ΅°
```
Claude Code β†’ LLM Router β†’ Multiple LLM Providers
                        β”β”€β”€ Anthropic (Claude-3 Opus/Sonnet/Haiku)
                        β”β”€β”€ Google (Gemini-Pro/Gemini-Ultra)
                        β””β”€β”€ OpenAI (GPT-4/GPT-3.5) [Future]
```

### λΌμ°ν„° μ»΄ν¬λ„νΈ
```
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚                    LLM Router System                       β”‚
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¤
β”‚ Request Handler β”‚ Model Selector β”‚ Load Balancer β”‚ Monitor β”‚
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”Όβ”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”Όβ”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”Όβ”€β”€β”€β”€β”€β”€β”€β”€β”€β”¤
β”‚ - Agent Auth    β”‚ - Task Analysisβ”‚ - Round Robin β”‚ - Metricsβ”‚
β”‚ - Request Parse β”‚ - Model Match  β”‚ - Health Checkβ”‚ - Loggingβ”‚
β”‚ - Response Fmt  β”‚ - Cost Calc    β”‚ - Failover   β”‚ - Alerts β”‚
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
```

---

## π“‹ λ‹¨κ³„λ³„ κµ¬ν„ κ³„ν

### Phase 1: κΈ°λ° μΈν”„λΌ κµ¬μ¶• (1-2μΌ)

#### 1.1 claude-code-router μ„¤μΉ λ° μ„¤μ •
```bash
# Router ν΄λ΅  λ° μ„¤μΉ
git clone https://github.com/musistudio/claude-code-router.git
cd claude-code-router
npm install

# κΈ°λ³Έ μ„¤μ • νμΌ μƒμ„±
cp config.example.json config.json
```

#### 1.2 κΈ°λ³Έ μ„¤μ • κµ¬μ„±
```json
{
  "server": {
    "port": 3000,
    "host": "localhost"
  },
  "providers": {
    "anthropic": {
      "enabled": true,
      "models": ["claude-3-opus", "claude-3-sonnet", "claude-3-haiku"]
    },
    "google": {
      "enabled": true,
      "models": ["gemini-pro"]
    }
  },
  "routing": {
    "strategy": "agent_based",
    "load_balancing": "round_robin"
  }
}
```

#### 1.3 Claude Code μ—°λ™ ν…μ¤νΈ
```python
# μ—°λ™ ν…μ¤νΈ μ¤ν¬λ¦½νΈ
import requests

def test_router_connection():
    router_url = "http://localhost:3000/api/chat"
    test_payload = {
        "agent": "data_agent",
        "message": "Hello from Claude Code",
        "model_preference": "cost_efficient"
    }

    response = requests.post(router_url, json=test_payload)
    return response.status_code == 200
```

### Phase 2: μ—μ΄μ „νΈ ν†µν•© (2-3μΌ)

#### 2.1 Agent-Router μΈν„°νμ΄μ¤ κµ¬ν„
```python
# Project/shared/llm_router_client.py
class LLMRouterClient:
    def __init__(self, router_url="http://localhost:3000"):
        self.router_url = router_url
        self.agent_configs = load_agent_model_config()

    def route_request(self, agent_name, task_type, message, **kwargs):
        """μ—μ΄μ „νΈ μ”μ²­μ„ μ μ ν• LLMμΌλ΅ λΌμ°ν…"""
        payload = {
            "agent": agent_name,
            "task": task_type,
            "message": message,
            "preferences": self._get_agent_preferences(agent_name),
            **kwargs
        }

        return self._send_request(payload)

    def _get_agent_preferences(self, agent_name):
        """agent_model.yamlμ—μ„ μ—μ΄μ „νΈλ³„ μ„ νΈλ„ λ΅λ“"""
        config = self.agent_configs.get(agent_name, {})
        return {
            "primary_model": config.get("primary_model"),
            "fallback_model": config.get("fallback_model"),
            "strategy": config.get("model_selection_strategy")
        }
```

#### 2.2 κ° μ—μ΄μ „νΈλ³„ λΌμ°ν„° ν΄λΌμ΄μ–ΈνΈ ν†µν•©
```python
# Project/indicator/data_agent_main.py
from shared.llm_router_client import LLMRouterClient

class DataAgent:
    def __init__(self):
        self.router = LLMRouterClient()

    def process_data_request(self, data_type, parameters):
        # LLM λΌμ°ν„°λ¥Ό ν†µν•΄ μ”μ²­ μ²λ¦¬
        response = self.router.route_request(
            agent_name="data_agent",
            task_type="data_processing",
            message=f"Process {data_type} data with {parameters}",
            context="large_dataset" if len(parameters) > 1000 else "normal"
        )

        return self._parse_response(response)
```

### Phase 3: λ¨λΈ μµμ ν™” (3-4μΌ)

#### 3.1 μ‘μ—…λ³„ λ¨λΈ λ§¤ν•‘ κµ¬ν„
```yaml
# config/task_model_mapping.yaml
task_mappings:
  data_processing:
    large_dataset: "gemini-pro"
    normal_dataset: "claude-3-sonnet"
    simple_calculation: "claude-3-haiku"

  strategy_development:
    complex_strategy: "claude-3-opus"
    signal_generation: "claude-3-sonnet"
    parameter_optimization: "gemini-pro"

  service_operations:
    backtesting: "claude-3-sonnet"
    order_execution: "claude-3-haiku"
    risk_monitoring: "claude-3-sonnet"
```

#### 3.2 λ™μ  λ¨λΈ μ„ νƒ λ΅μ§
```python
class ModelSelector:
    def select_optimal_model(self, agent, task, context):
        # λΉ„μ© κ³ λ ¤
        if context.get("budget_constraint", False):
            return self._get_cost_efficient_model(task)

        # μ„±λ¥ μ°μ„ 
        if context.get("quality_critical", False):
            return self._get_high_quality_model(task)

        # μ†λ„ μ°μ„ 
        if context.get("time_critical", False):
            return self._get_fast_model(task)

        # κΈ°λ³Έ μ„ νƒ
        return self._get_default_model(agent, task)
```

### Phase 4: λ¨λ‹ν„°λ§ λ° μµμ ν™” (2-3μΌ)

#### 4.1 μ„±λ¥ λ¨λ‹ν„°λ§ μ‹μ¤ν…
```python
# monitoring/llm_performance_monitor.py
class LLMPerformanceMonitor:
    def __init__(self):
        self.metrics = {
            "response_times": {},
            "success_rates": {},
            "cost_tracking": {},
            "model_usage": {}
        }

    def log_request(self, agent, model, task, start_time, end_time, cost, success):
        """μ”μ²­ λ©”νΈλ¦­ λ΅κΉ…"""
        response_time = end_time - start_time

        self.metrics["response_times"][model] = self.metrics["response_times"].get(model, [])
        self.metrics["response_times"][model].append(response_time)

        # λΉ„μ© μ¶”μ 
        self.metrics["cost_tracking"][agent] = self.metrics["cost_tracking"].get(agent, 0)
        self.metrics["cost_tracking"][agent] += cost

    def generate_daily_report(self):
        """μΌμΌ μ„±λ¥ λ¦¬ν¬νΈ μƒμ„±"""
        return {
            "total_requests": sum(len(times) for times in self.metrics["response_times"].values()),
            "average_response_time": self._calculate_avg_response_time(),
            "total_cost": sum(self.metrics["cost_tracking"].values()),
            "model_distribution": self._calculate_model_distribution()
        }
```

#### 4.2 μλ™ μµμ ν™” μ‹μ¤ν…
```python
class AutoOptimizer:
    def optimize_model_selection(self):
        """μ„±λ¥ λ°μ΄ν„° κΈ°λ° λ¨λΈ μ„ νƒ μµμ ν™”"""
        monitor = LLMPerformanceMonitor()
        daily_report = monitor.generate_daily_report()

        # λΉ„μ© ν¨μ¨μ„± λ¶„μ„
        if daily_report["total_cost"] > self.cost_threshold:
            self._shift_to_cost_efficient_models()

        # μ‘λ‹µ μ‹κ°„ μµμ ν™”
        if daily_report["average_response_time"] > self.time_threshold:
            self._shift_to_faster_models()
```

---

## π”§ κΈ°μ μ  κµ¬ν„ μ„Έλ¶€μ‚¬ν•­

### API μΈν„°νμ΄μ¤ μ„¤κ³„
```typescript
// Router API μ—”λ“ν¬μΈνΈ
interface RouterRequest {
  agent: string;
  task: string;
  message: string;
  preferences?: {
    model?: string;
    strategy?: "quality" | "cost" | "speed";
    max_tokens?: number;
    temperature?: number;
  };
  context?: {
    dataset_size?: "small" | "medium" | "large";
    time_critical?: boolean;
    budget_constraint?: boolean;
  };
}

interface RouterResponse {
  model_used: string;
  response: string;
  metadata: {
    cost: number;
    response_time: number;
    tokens_used: number;
    provider: string;
  };
}
```

### λ΅λ“ λ°Έλ°μ‹± μ „λµ
```javascript
// λΌμ΄λ“ λ΅λΉ λ΅λ“ λ°Έλ°μ‹±
class LoadBalancer {
  constructor() {
    this.modelQueues = {
      "claude-3-opus": [],
      "claude-3-sonnet": [],
      "gemini-pro": []
    };
    this.currentIndex = {};
  }

  selectModel(availableModels, strategy = "round_robin") {
    switch(strategy) {
      case "round_robin":
        return this.roundRobinSelect(availableModels);
      case "least_loaded":
        return this.leastLoadedSelect(availableModels);
      case "health_based":
        return this.healthBasedSelect(availableModels);
    }
  }
}
```

### Gemini λ¨λΈ ν†µν•©
```python
# providers/gemini_provider.py
class GeminiProvider:
    def __init__(self, api_key):
        self.api_key = api_key
        self.base_url = "https://generativelanguage.googleapis.com/v1/models"

    def generate_response(self, prompt, model="gemini-pro", **kwargs):
        """Gemini API νΈμ¶"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        payload = {
            "contents": [{"parts": [{"text": prompt}]}],
            "generationConfig": {
                "temperature": kwargs.get("temperature", 0.7),
                "maxOutputTokens": kwargs.get("max_tokens", 1000)
            }
        }

        response = requests.post(
            f"{self.base_url}/{model}:generateContent",
            headers=headers,
            json=payload
        )

        return self._parse_gemini_response(response)
```

---

## π“ λ¨λ‹ν„°λ§ λ° μ•λ¦Ό μ²΄κ³„

### μ‹¤μ‹κ°„ λ¨λ‹ν„°λ§ λ€μ‹λ³΄λ“
```python
# monitoring/dashboard.py
class RouterDashboard:
    def __init__(self):
        self.app = Flask(__name__)
        self.setup_routes()

    def setup_routes(self):
        @self.app.route("/dashboard")
        def dashboard():
            metrics = self.get_current_metrics()
            return render_template("dashboard.html", metrics=metrics)

        @self.app.route("/api/metrics")
        def api_metrics():
            return jsonify(self.get_current_metrics())

    def get_current_metrics(self):
        return {
            "active_models": self.get_active_models(),
            "request_rate": self.get_request_rate(),
            "average_response_time": self.get_avg_response_time(),
            "cost_per_hour": self.get_hourly_cost(),
            "error_rate": self.get_error_rate()
        }
```

### μ•λ¦Ό μ‹μ¤ν…
```python
# monitoring/alerts.py
class AlertManager:
    def __init__(self):
        self.thresholds = {
            "high_cost": 100,  # USD per hour
            "slow_response": 10,  # seconds
            "high_error_rate": 0.05  # 5%
        }

    def check_alerts(self, metrics):
        alerts = []

        if metrics["cost_per_hour"] > self.thresholds["high_cost"]:
            alerts.append({
                "type": "high_cost",
                "message": f"Hourly cost exceeded: ${metrics['cost_per_hour']:.2f}",
                "severity": "warning"
            })

        if metrics["error_rate"] > self.thresholds["high_error_rate"]:
            alerts.append({
                "type": "high_error_rate",
                "message": f"Error rate: {metrics['error_rate']:.1%}",
                "severity": "critical"
            })

        return alerts
```

---

## π€ λ°°ν¬ λ° μ΄μ κ³„ν

### κ°λ° ν™κ²½ κµ¬μ„±
```bash
# κ°λ° ν™κ²½ μ„¤μ •
mkdir llm-router-dev
cd llm-router-dev

# Docker Composeλ΅ κ°λ° ν™κ²½ κµ¬μ„±
docker-compose up -d

# ν™κ²½λ³„ μ„¤μ •
cp config/development.json config/config.json
```

### ν”„λ΅λ•μ… λ°°ν¬
```yaml
# docker-compose.prod.yml
version: '3.8'
services:
  llm-router:
    image: musistudio/claude-code-router:latest
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
    volumes:
      - ./config:/app/config
    restart: unless-stopped

  redis:
    image: redis:alpine
    volumes:
      - redis-data:/data
    restart: unless-stopped

  monitoring:
    image: prometheus/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
```

### λ°±μ—… λ° λ³µκµ¬ κ³„ν
```bash
# μ„¤μ • λ°±μ—…
tar -czf router-config-backup-$(date +%Y%m%d).tar.gz config/

# λ΅κ·Έ μ•„μΉ΄μ΄λΈ
find logs/ -name "*.log" -mtime +7 -exec gzip {} \;

# λ©”νΈλ¦­ λ°μ΄ν„° λ°±μ—…
pg_dump metrics_db > metrics-backup-$(date +%Y%m%d).sql
```

---

## π“ μ„±κ³µ μ§€ν‘ λ° KPI

### κΈ°μ μ  μ§€ν‘
- **μ‘λ‹µ μ‹κ°„**: ν‰κ·  < 3μ΄
- **κ°€μ©μ„±**: > 99.9%
- **μ—λ¬μ¨**: < 1%
- **λ¨λΈ λ‹¤μ–‘μ„±**: μµμ† 3κ° λ¨λΈ ν™μ©

### λΉ„μ¦λ‹μ¤ μ§€ν‘
- **λΉ„μ© μ κ°**: 30% μ΄μƒ
- **μ²λ¦¬λ‰ μ¦κ°€**: 50% μ΄μƒ
- **μ‚¬μ©μ λ§μ΅±λ„**: 9/10 μ΄μƒ

### λ¨λ‹ν„°λ§ λ€μƒ
```python
# KPI μ¶”μ 
kpis = {
    "technical": {
        "avg_response_time": "< 3000ms",
        "uptime": "> 99.9%",
        "error_rate": "< 1%",
        "throughput": "> 1000 requests/hour"
    },
    "business": {
        "cost_reduction": "> 30%",
        "model_utilization": {
            "claude": "< 70%",
            "gemini": "> 30%"
        }
    }
}
```

---

## π”® ν–¥ν›„ ν™•μ¥ κ³„ν

### λ‹¨κΈ° ν™•μ¥ (1-3κ°μ›”)
- **OpenAI GPT λ¨λΈ μ¶”κ°€**
- **Cohere λ¨λΈ ν†µν•©**
- **λ” μ •κµν• μ‘μ—…λ³„ λ¨λΈ λ§¤ν•‘**

### μ¤‘κΈ° ν™•μ¥ (3-6κ°μ›”)
- **λ¨Έμ‹ λ¬λ‹ κΈ°λ° λ¨λΈ μ„ νƒ**
- **A/B ν…μ¤ν… ν”„λ μ„μ›ν¬**
- **μ‹¤μ‹κ°„ μ„±λ¥ μµμ ν™”**

### μ¥κΈ° λΉ„μ „ (6κ°μ›”+)
- **μμ²΄ LLM λ¨λΈ ν†µν•©**
- **μ—£μ§€ μ»΄ν“¨ν… μ§€μ›**
- **λ©€ν‹° λ¦¬μ „ λ°°ν¬**

---

## π― μ‹¤ν–‰ μΌμ •

| μ£Όμ°¨ | μ£Όμ” μ‘μ—… | λ‹΄λ‹Ή | μ™„λ£ κΈ°μ¤€ |
|------|----------|------|-----------|
| 1μ£Όμ°¨ | λΌμ°ν„° μ„¤μΉ λ° κΈ°λ³Έ μ„¤μ • | μ „μ²΄ν€ | κΈ°λ³Έ μ—°λ™ ν…μ¤νΈ μ™„λ£ |
| 2μ£Όμ°¨ | μ—μ΄μ „νΈ ν†µν•© | κ° μ—μ΄μ „νΈν€ | λ¨λ“  μ—μ΄μ „νΈ λΌμ°ν„° μ—°λ™ |
| 3μ£Όμ°¨ | λ¨λΈ μµμ ν™” κµ¬ν„ | μ „λµν€ | λ™μ  λ¨λΈ μ„ νƒ μ‘λ™ |
| 4μ£Όμ°¨ | λ¨λ‹ν„°λ§ μ‹μ¤ν… κµ¬μ¶• | μΈν”„λΌν€ | λ€μ‹λ³΄λ“ λ° μ•λ¦Ό μ‹μ¤ν… |
| 5μ£Όμ°¨ | ν…μ¤νΈ λ° μµμ ν™” | μ „μ²΄ν€ | μ„±λ¥ λ©ν‘ λ‹¬μ„± |
| 6μ£Όμ°¨ | ν”„λ΅λ•μ… λ°°ν¬ | DevOpsν€ | μ‹¤μ„λΉ„μ¤ μ μ© μ™„λ£ |

---

**π¨ μ¤‘μ”**: μ΄ κ³„νμ€ claude-code-routerμ μ„±μ™λ„μ™€ μ•μ •μ„±μ— λ”°λΌ μ΅°μ •λ  μ μμµλ‹λ‹¤.

*κ³„ν λ²„μ „: 1.0 | μµμΆ… μ—…λ°μ΄νΈ: 2025-09-15*